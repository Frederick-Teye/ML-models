{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frederick-Teye/ML-models/blob/main/last_last.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17264ce-78ac-4910-a5bb-52f2abb4b47e",
      "metadata": {
        "id": "c17264ce-78ac-4910-a5bb-52f2abb4b47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d04ec647-62ab-43a6-e625-1c29d19fbe78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
              "0  Female  56.0             0              0         No Info  37.23   \n",
              "1    Male  29.0             0              0           never  27.32   \n",
              "2  Female  26.0             0              0         No Info  27.32   \n",
              "3    Male  50.0             0              0         current  27.32   \n",
              "4  Female  56.0             0              0           never  38.48   \n",
              "\n",
              "   hbA1c_level  blood_glucose_level  diabetes  \n",
              "0          6.5                   80         0  \n",
              "1          3.5                  160         0  \n",
              "2          4.0                  145         0  \n",
              "3          5.0                  145         0  \n",
              "4          5.7                  155         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c918622-9dc6-4f68-afd2-2c84194c84be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>smoking_history</th>\n",
              "      <th>bmi</th>\n",
              "      <th>hbA1c_level</th>\n",
              "      <th>blood_glucose_level</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Info</td>\n",
              "      <td>37.23</td>\n",
              "      <td>6.5</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>never</td>\n",
              "      <td>27.32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Info</td>\n",
              "      <td>27.32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>current</td>\n",
              "      <td>27.32</td>\n",
              "      <td>5.0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>never</td>\n",
              "      <td>38.48</td>\n",
              "      <td>5.7</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c918622-9dc6-4f68-afd2-2c84194c84be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c918622-9dc6-4f68-afd2-2c84194c84be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c918622-9dc6-4f68-afd2-2c84194c84be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c805e74a-e1ef-450b-a12c-3da54aabbba5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c805e74a-e1ef-450b-a12c-3da54aabbba5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c805e74a-e1ef-450b-a12c-3da54aabbba5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ziya_data",
              "summary": "{\n  \"name\": \"ziya_data\",\n  \"rows\": 17000,\n  \"fields\": [\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.483865092644045,\n        \"min\": 0.08,\n        \"max\": 80.0,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          51.0,\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hypertension\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heart_disease\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoking_history\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"No Info\",\n          \"never\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.48984736386505,\n        \"min\": 10.77,\n        \"max\": 88.72,\n        \"num_unique_values\": 3324,\n        \"samples\": [\n          17.35,\n          24.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hbA1c_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2773176429765467,\n        \"min\": 3.5,\n        \"max\": 9.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          6.5,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_glucose_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56,\n        \"min\": 80,\n        \"max\": 300,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          80,\n          160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "ziya_data = pd.read_csv('/content/drive/MyDrive/diabetes_data/cleaned_ziya_data.csv')\n",
        "ziya_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692fd18c-360f-434c-ac27-c4c5baadaf99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "692fd18c-360f-434c-ac27-c4c5baadaf99",
        "outputId": "f7526753-4eaa-4fbd-de6c-82951cd75bb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender  hypertension  heart_disease\n",
              "Female  0             0                7620\n",
              "                      1                 439\n",
              "        1             0                1207\n",
              "                      1                 184\n",
              "Male    0             0                5674\n",
              "                      1                 673\n",
              "        1             0                 979\n",
              "                      1                 224\n",
              "Name: diabetes, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">Female</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>7620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>1207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">Male</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>5674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "ziya_data.groupby(['gender', 'hypertension', 'heart_disease']).diabetes.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a966b3-ee91-4781-a5a4-5af14a5ca533",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "51a966b3-ee91-4781-a5a4-5af14a5ca533",
        "outputId": "03c6cdfd-8c84-4b4d-d77a-407b94290dcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diabetes\n",
              "0    8500\n",
              "1    8500\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diabetes</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "ziya_data.diabetes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "df3mX8f8PZky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3d503f-ce9a-47f4-b538-18e41959e222"
      },
      "id": "df3mX8f8PZky",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Codes"
      ],
      "metadata": {
        "id": "LShAFqG6WGDU"
      },
      "id": "LShAFqG6WGDU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf34c66-2960-459e-982d-ef35afef3150",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cf34c66-2960-459e-982d-ef35afef3150",
        "outputId": "1fc7d616-2af8-4218-b681-9d78e4ce7dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation at Threshold = 0.50\n",
            "==================================================\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.9009\n",
            "Recall: 0.9194\n",
            "F1-Score: 0.9100\n",
            "ROC-AUC: 0.9766\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      1700\n",
            "           1       0.90      0.92      0.91      1700\n",
            "\n",
            "    accuracy                           0.91      3400\n",
            "   macro avg       0.91      0.91      0.91      3400\n",
            "weighted avg       0.91      0.91      0.91      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])  # Feature matrix\n",
        "y = ziya_data['diabetes']  # Target variable\n",
        "\n",
        "# Train-test split (stratify to maintain balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Categorical Encoding (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# XGBoost Classifier (No class weighting for balanced data)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=900,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.8,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold = 0.5  # Standard for balanced data\n",
        "y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "# Model Evaluation\n",
        "print(f\"\\nEvaluation at Threshold = {threshold:.2f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Store metrics for visualization\n",
        "recall_model0 = recall_score(y_test, y_pred)\n",
        "precision_model0 = precision_score(y_test, y_pred)\n",
        "f1_model0 = f1_score(y_test, y_pred)\n",
        "accuracy_model0 = accuracy_score(y_test, y_pred)\n",
        "roc_auc_model0 = roc_auc_score(y_test, y_pred_proba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c47a17f-4002-4130-ac64-f04b5171dede",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c47a17f-4002-4130-ac64-f04b5171dede",
        "outputId": "811d61b1-ae10-4332-c7fe-7d888d968c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation at Threshold = 0.50\n",
            "==================================================\n",
            "Accuracy: 0.9088\n",
            "Precision: 0.9017\n",
            "Recall: 0.9176\n",
            "F1-Score: 0.9096\n",
            "ROC-AUC: 0.9767\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      1700\n",
            "           1       0.90      0.92      0.91      1700\n",
            "\n",
            "    accuracy                           0.91      3400\n",
            "   macro avg       0.91      0.91      0.91      3400\n",
            "weighted avg       0.91      0.91      0.91      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])  # Feature matrix\n",
        "y = ziya_data['diabetes']  # Target variable\n",
        "\n",
        "# Train-test split (stratify to maintain balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Categorical Encoding (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# XGBoost Classifier (No class weighting for balanced data)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1000,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.7,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold = 0.5  # Standard for balanced data\n",
        "y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "# Model Evaluation\n",
        "print(f\"\\nEvaluation at Threshold = {threshold:.2f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Store metrics for visualization\n",
        "recall_model0 = recall_score(y_test, y_pred)\n",
        "precision_model0 = precision_score(y_test, y_pred)\n",
        "f1_model0 = f1_score(y_test, y_pred)\n",
        "accuracy_model0 = accuracy_score(y_test, y_pred)\n",
        "roc_auc_model0 = roc_auc_score(y_test, y_pred_proba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "086aa2fd-9a7d-4ace-baa4-549cafb54e30",
      "metadata": {
        "id": "086aa2fd-9a7d-4ace-baa4-549cafb54e30"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c19f9dd-95aa-4fb8-ca51-a333d104245f",
        "id": "F-bciWMGPFuJ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation at Threshold = 0.51\n",
            "==================================================\n",
            "Accuracy: 0.9079\n",
            "Precision: 0.9030\n",
            "Recall: 0.9141\n",
            "F1-Score: 0.9085\n",
            "ROC-AUC: 0.9766\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.90      0.91      1700\n",
            "           1       0.90      0.91      0.91      1700\n",
            "\n",
            "    accuracy                           0.91      3400\n",
            "   macro avg       0.91      0.91      0.91      3400\n",
            "weighted avg       0.91      0.91      0.91      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])  # Feature matrix\n",
        "y = ziya_data['diabetes']  # Target variable\n",
        "\n",
        "# Train-test split (stratify to maintain balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Categorical Encoding (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# XGBoost Classifier (No class weighting for balanced data)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1000,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.8,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold = 0.51\n",
        "y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "# Model Evaluation\n",
        "print(f\"\\nEvaluation at Threshold = {threshold:.2f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Store metrics for visualization\n",
        "recall_model0 = recall_score(y_test, y_pred)\n",
        "precision_model0 = precision_score(y_test, y_pred)\n",
        "f1_model0 = f1_score(y_test, y_pred)\n",
        "accuracy_model0 = accuracy_score(y_test, y_pred)\n",
        "roc_auc_model0 = roc_auc_score(y_test, y_pred_proba)\n"
      ],
      "id": "F-bciWMGPFuJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LPkTQ3uiPFLN"
      },
      "id": "LPkTQ3uiPFLN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze and Visualize XGBoost Models"
      ],
      "metadata": {
        "id": "7W-5uIYJWa2a"
      },
      "id": "7W-5uIYJWa2a"
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])  # Feature matrix\n",
        "y = ziya_data['diabetes']  # Target variable\n",
        "\n",
        "# Train-test split (stratify to maintain balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Categorical Encoding (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "# Initialize a dictionary to store model information\n",
        "model_info = {}\n",
        "\n",
        "# Model 1: XGBoost (n_estimators=900, subsample=0.8)\n",
        "xgb_model1 = XGBClassifier(\n",
        "    n_estimators=900,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.8,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model1.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba1 = xgb_model1.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold1 = 0.5  # Standard for balanced data\n",
        "y_pred1 = (y_pred_proba1 >= threshold1).astype(int)\n",
        "\n",
        "# Store model information\n",
        "model_info['XGBoost_1'] = {\n",
        "    'threshold': threshold1,\n",
        "    'n_estimators': 900,\n",
        "    'subsample': 0.8,\n",
        "    'accuracy': accuracy_score(y_test, y_pred1),\n",
        "    'precision': precision_score(y_test, y_pred1),\n",
        "    'recall': recall_score(y_test, y_pred1),\n",
        "    'f1_score': f1_score(y_test, y_pred1),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba1)\n",
        "}\n",
        "\n",
        "\n",
        "# Model 2: XGBoost (n_estimators=1000, subsample=0.7)\n",
        "# ... (Similar code structure as model 1, but with different parameters) ...\n",
        "xgb_model1 = XGBClassifier(\n",
        "    n_estimators=1000,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.7,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model1.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba1 = xgb_model1.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold1 = 0.5  # Standard for balanced data\n",
        "y_pred1 = (y_pred_proba1 >= threshold1).astype(int)\n",
        "\n",
        "# Store model information\n",
        "model_info['XGBoost_2'] = {\n",
        "    'threshold': threshold1,\n",
        "    'n_estimators': 1000,\n",
        "    'subsample': 0.7,\n",
        "    'accuracy': accuracy_score(y_test, y_pred1),\n",
        "    'precision': precision_score(y_test, y_pred1),\n",
        "    'recall': recall_score(y_test, y_pred1),\n",
        "    'f1_score': f1_score(y_test, y_pred1),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba1)\n",
        "}\n",
        "\n",
        "# Model 3: XGBoost (n_estimators=1000, subsample=0.8, threshold=0.51)\n",
        "# ... (Similar code structure as model 1, but with different parameters) ...\n",
        "xgb_model1 = XGBClassifier(\n",
        "    n_estimators=1000,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.8,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model1.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba1 = xgb_model1.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold1 = 0.51  # Standard for balanced data\n",
        "y_pred1 = (y_pred_proba1 >= threshold1).astype(int)\n",
        "\n",
        "# Store model information\n",
        "model_info['XGBoost_3'] = {\n",
        "    'threshold': threshold1,\n",
        "    'n_estimators': 1000,\n",
        "    'subsample': 0.8,\n",
        "    'accuracy': accuracy_score(y_test, y_pred1),\n",
        "    'precision': precision_score(y_test, y_pred1),\n",
        "    'recall': recall_score(y_test, y_pred1),\n",
        "    'f1_score': f1_score(y_test, y_pred1),\n",
        "    'roc_auc': roc_auc_score(y_test, y_pred_proba1)\n",
        "}\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "aM_VygcCZmiE"
      },
      "id": "aM_VygcCZmiE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIqQMnxrOd6M"
      },
      "id": "HIqQMnxrOd6M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Create a Pandas DataFrame for Model Comparison"
      ],
      "metadata": {
        "id": "oI9esRwCW4Vx"
      },
      "id": "oI9esRwCW4Vx"
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = pd.DataFrame.from_dict(model_info, orient='index')\n",
        "model_df.reset_index(inplace=True)\n",
        "model_df.rename(columns={'index': 'Model'}, inplace=True)"
      ],
      "metadata": {
        "id": "-X1q1n1IOdna"
      },
      "id": "-X1q1n1IOdna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Visualize Model Performance using Seaborn"
      ],
      "metadata": {
        "id": "5UZjUHy9XDSx"
      },
      "id": "5UZjUHy9XDSx"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Melt the DataFrame to create a long-form dataset for plotting\n",
        "melted_df = pd.melt(\n",
        "    model_df,\n",
        "    id_vars=['Model'],\n",
        "    value_vars=['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc'],\n",
        "    var_name='Metric',\n",
        "    value_name='Score'\n",
        ")\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='Model', y='Score', hue='Metric', data=melted_df)\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    ax.text(p.get_x() + p.get_width() / 2., height + 0.01,\n",
        "            f'{height:.3f}', ha=\"center\")\n",
        "\n",
        "# Adjust legend position to avoid overlapping\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "NS1h0cF2OdP8",
        "outputId": "908c5c93-c92b-4588-fc5b-a7da53d4b84a"
      },
      "id": "NS1h0cF2OdP8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Display the Model Tuning Table"
      ],
      "metadata": {
        "id": "E-O9Qgk0XT8D"
      },
      "id": "E-O9Qgk0XT8D"
    },
    {
      "cell_type": "code",
      "source": [
        "# You can directly display the model_df DataFrame using:\n",
        "display(model_df)\n",
        "\n",
        "# Or, you can use a library like tabulate for better formatting:\n",
        "# from tabulate import tabulate\n",
        "# print(tabulate(model_df, headers='keys', tablefmt='psql'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "DYd_xB2BO-GZ",
        "outputId": "831b03da-86a3-433a-8f7d-3104cd587a80"
      },
      "id": "DYd_xB2BO-GZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Model  threshold  n_estimators  subsample  accuracy  precision  \\\n",
              "0  XGBoost_1       0.50           900        0.8  0.909118   0.900865   \n",
              "1  XGBoost_2       0.50          1000        0.7  0.908824   0.901734   \n",
              "2  XGBoost_3       0.51          1000        0.8  0.907941   0.902963   \n",
              "\n",
              "     recall  f1_score   roc_auc  \n",
              "0  0.919412  0.910044  0.976608  \n",
              "1  0.917647  0.909621  0.976663  \n",
              "2  0.914118  0.908506  0.976608  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7563b78-9d62-4f58-ad3d-480bd0657d7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>threshold</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>subsample</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost_1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>900</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.909118</td>\n",
              "      <td>0.900865</td>\n",
              "      <td>0.919412</td>\n",
              "      <td>0.910044</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost_2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.908824</td>\n",
              "      <td>0.901734</td>\n",
              "      <td>0.917647</td>\n",
              "      <td>0.909621</td>\n",
              "      <td>0.976663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost_3</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.907941</td>\n",
              "      <td>0.902963</td>\n",
              "      <td>0.914118</td>\n",
              "      <td>0.908506</td>\n",
              "      <td>0.976608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7563b78-9d62-4f58-ad3d-480bd0657d7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7563b78-9d62-4f58-ad3d-480bd0657d7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7563b78-9d62-4f58-ad3d-480bd0657d7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddfed1e6-5463-4397-a881-e0ca70f1d47c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddfed1e6-5463-4397-a881-e0ca70f1d47c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddfed1e6-5463-4397-a881-e0ca70f1d47c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_22604a40-b4ca-43ab-9e3d-dda65a0d9b36\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_22604a40-b4ca-43ab-9e3d-dda65a0d9b36 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "model_df",
              "summary": "{\n  \"name\": \"model_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"XGBoost_1\",\n          \"XGBoost_2\",\n          \"XGBoost_3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"threshold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005773502691896262,\n        \"min\": 0.5,\n        \"max\": 0.51,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.51,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_estimators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 900,\n        \"max\": 1000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1000,\n          900\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subsample\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05773502691896263,\n        \"min\": 0.7,\n        \"max\": 0.8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.7,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0006122547057253008,\n        \"min\": 0.9079411764705883,\n        \"max\": 0.9091176470588235,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9091176470588235,\n          0.9088235294117647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010545457424064183,\n        \"min\": 0.9008645533141211,\n        \"max\": 0.9029633933759442,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9008645533141211,\n          0.9017341040462428\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002695632761738761,\n        \"min\": 0.9141176470588235,\n        \"max\": 0.9194117647058824,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9194117647058824,\n          0.9176470588235294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007942264747379079,\n        \"min\": 0.9085062847120725,\n        \"max\": 0.9100436681222708,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9100436681222708,\n          0.9096209912536443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.196402874401666e-05,\n        \"min\": 0.976607785467128,\n        \"max\": 0.9766631487889272,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9766631487889272,\n          0.976607785467128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Choose XGBoost_1 for Diabetic Diagnosis?\n",
        "\n",
        "### Balanced Performance\n",
        "- **Accuracy**: XGBoost_1 achieves an impressive accuracy of 90.91%, ensuring reliable predictions.\n",
        "- **Precision**: With a precision of 90.09%, it minimizes false positives, which is crucial for avoiding misdiagnoses.\n",
        "- **Recall**: Its high recall of 91.94% ensures that diabetic cases are identified effectively, reducing the chances of false negatives.\n",
        "- **F1-Score**: A well-balanced F1-score of 91.00% indicates the model's ability to balance precision and recall effectively.\n",
        "\n",
        "### Strong ROC-AUC\n",
        "- XGBoost_1 has a **ROC-AUC of 97.66%**, demonstrating excellent ability to distinguish between diabetic and non-diabetic cases.\n",
        "\n",
        "### Threshold and Parameters\n",
        "- The model uses a **threshold of 0.5**, which balances sensitivity (recall) and specificity (precision) effectively.\n",
        "- With **900 estimators** and a **subsample ratio of 0.8**, XGBoost_1 processes diverse subsets of data, improving generalization without overfitting.\n",
        "\n",
        "### Why Not Other Models?\n",
        "1. **XGBoost_2**:\n",
        "   - While very close in metrics, it has a slightly lower recall (91.76%) compared to XGBoost_1, which is crucial for identifying all diabetic cases.\n",
        "2. **XGBoost_3**:\n",
        "   - Although it has higher precision (90.29%), its recall (91.41%) is lower, making it less favorable for medical use where minimizing false negatives is key.\n",
        "\n",
        "### Final Recommendation\n",
        "XGBoost_1 is the best choice due to its balanced metrics, strong ROC-AUC, and reliability in identifying diabetic cases while minimizing misdiagnoses.\n"
      ],
      "metadata": {
        "id": "Cd21EBVhn9U5"
      },
      "id": "Cd21EBVhn9U5"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCazr9pSOzFK"
      },
      "id": "gCazr9pSOzFK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQ2zPAp-OzCU"
      },
      "id": "yQ2zPAp-OzCU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hao5xP2FPENt"
      },
      "id": "hao5xP2FPENt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qEs3kN65O9ij"
      },
      "id": "qEs3kN65O9ij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_jcaiALO9f3"
      },
      "id": "E_jcaiALO9f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6KtAECvO9c6"
      },
      "id": "R6KtAECvO9c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b22a00-20f8-4b0d-bc7b-28c2a34aeb5a",
      "metadata": {
        "id": "30b22a00-20f8-4b0d-bc7b-28c2a34aeb5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The hpelm models are bad, so ignore them"
      ],
      "metadata": {
        "id": "7TqBx0A6Xw7B"
      },
      "id": "7TqBx0A6Xw7B"
    },
    {
      "cell_type": "markdown",
      "id": "5537458b-4b47-4ae0-b6ab-7e40872f00de",
      "metadata": {
        "id": "5537458b-4b47-4ae0-b6ab-7e40872f00de"
      },
      "source": [
        "# hpelm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VvN_esWIGwUt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvN_esWIGwUt",
        "outputId": "e3fb4b95-1e73-4b80-f94c-66756649edbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hpelm in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from hpelm) (0.19)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.11/dist-packages (from hpelm) (1.3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hpelm) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.12 in /usr/local/lib/python3.11/dist-packages (from hpelm) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hpelm) (1.17.0)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.11/dist-packages (from hpelm) (3.10.2)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (2.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (24.2)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (9.0.0)\n",
            "Requirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (3.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from tables->hpelm) (4.13.0)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (1.9.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (1.1.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (4.3.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->hpelm) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables->hpelm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables->hpelm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables->hpelm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->blosc2>=2.3.0->tables->hpelm) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install hpelm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de71911-b82f-46b9-8f05-1a2318c55e26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9de71911-b82f-46b9-8f05-1a2318c55e26",
        "outputId": "6976edf5-1ad3-49bc-ae40-c523f5e72784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " X_train_preprocessed.shape[1]:\n",
            "  12\n",
            "y_train.shape[1]:\n",
            " 2\n",
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8685\n",
            "Precision: 0.8705\n",
            "Recall: 0.8659\n",
            "F1-Score: 0.8682\n",
            "ROC-AUC: 0.9379\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87      1700\n",
            "           1       0.87      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "print(f' X_train_preprocessed.shape[1]:\\n  {X_train_preprocessed.shape[1]}')\n",
        "print(f'y_train.shape[1]:\\n {y_train.shape[1]}')\n",
        "\n",
        "# Define the ELM model\n",
        "num_neurons = 3000  # Adjust as needed\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\")  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Apply threshold for classification\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12fb87b-98a2-40bd-b3d0-a28e3f4e0cf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b12fb87b-98a2-40bd-b3d0-a28e3f4e0cf1",
        "outputId": "92d93b35-08d4-45ef-b626-8fede4ffa344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8735\n",
            "Precision: 0.8753\n",
            "Recall: 0.8712\n",
            "F1-Score: 0.8732\n",
            "ROC-AUC: 0.9425\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Define the ELM model\n",
        "num_neurons = 3000  # Adjust as needed\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\")  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Apply threshold for classification\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7ac0ab-cb56-4b79-97f2-b25f9c00ce16",
      "metadata": {
        "id": "6c7ac0ab-cb56-4b79-97f2-b25f9c00ce16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c6439c-d175-4fc0-bb9d-c1cee7a3d68f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46c6439c-d175-4fc0-bb9d-c1cee7a3d68f",
        "outputId": "478cd042-4242-4412-f84f-c5be545d0569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8256\n",
            "Precision: 0.7878\n",
            "Recall: 0.8912\n",
            "F1-Score: 0.8363\n",
            "ROC-AUC: 0.8821\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.76      0.81      1700\n",
            "           1       0.79      0.89      0.84      1700\n",
            "\n",
            "    accuracy                           0.83      3400\n",
            "   macro avg       0.83      0.83      0.82      3400\n",
            "weighted avg       0.83      0.83      0.82      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load data (same as HPELM)\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Feature Engineering: Create BMI categories\n",
        "X['bmi_category'] = pd.cut(X['bmi'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease',\n",
        "       'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history', 'bmi_category']  # Added bmi_category\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', RobustScaler(), num_features),  # Changed to RobustScaler\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features)  # Removed drop='first'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Dynamically adjust the number of neurons\n",
        "num_neurons = min(5000, X_train_preprocessed.shape[0] // 2)\n",
        "\n",
        "# Define the ELM model\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model with class weights\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\", W=class_weight_dict)  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Determine best threshold using Precision-Recall Curve\n",
        "precisions, recalls, thresholds = precision_recall_curve(np.argmax(y_test, axis=1), y_pred_proba[:, 1])\n",
        "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
        "\n",
        "# Apply optimized threshold\n",
        "y_pred = (y_pred_proba[:, 1] >= best_threshold).astype(int)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1e7dfd-9dde-4ff3-b682-1405eddaa7ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b1e7dfd-9dde-4ff3-b682-1405eddaa7ca",
        "outputId": "b5ce6352-7876-4e48-93a8-31dfc2a64fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8488\n",
            "Precision: 0.8317\n",
            "Recall: 0.8747\n",
            "F1-Score: 0.8526\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.84      1700\n",
            "           1       0.83      0.87      0.85      1700\n",
            "\n",
            "    accuracy                           0.85      3400\n",
            "   macro avg       0.85      0.85      0.85      3400\n",
            "weighted avg       0.85      0.85      0.85      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load data (same as HPELM)\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Feature Engineering: Create BMI categories\n",
        "X['bmi_category'] = pd.cut(X['bmi'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease',\n",
        "       'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history', 'bmi_category']  # Added bmi_category\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', RobustScaler(), num_features),  # Changed to RobustScaler\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features)  # Removed drop='first'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Dynamically adjust the number of neurons\n",
        "num_neurons = min(5000, X_train_preprocessed.shape[0] // 2)\n",
        "\n",
        "# Define the ELM model\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model with class weights\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\", W=class_weight_dict)  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Determine best threshold using Precision-Recall Curve\n",
        "precisions, recalls, thresholds = precision_recall_curve(np.argmax(y_test, axis=1), y_pred_proba[:, 1])\n",
        "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
        "\n",
        "# Apply optimized threshold\n",
        "y_pred = (y_pred_proba[:, 1] >= best_threshold).astype(int)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642e4170-59f9-4d9d-ac33-ea2f4a390f8c",
      "metadata": {
        "id": "642e4170-59f9-4d9d-ac33-ea2f4a390f8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0bafaf-6026-4e88-98b0-26db7580f8a7",
      "metadata": {
        "id": "0d0bafaf-6026-4e88-98b0-26db7580f8a7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87184bbe-ca4d-41a7-8c85-280e3e79e3b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87184bbe-ca4d-41a7-8c85-280e3e79e3b6",
        "outputId": "22cda195-1cb0-48aa-888a-3bcb1f329044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/hpelm/nnets/slfn.py:62: RuntimeWarning: overflow encountered in exp\n",
            "  self.func[\"sigm\"] = lambda X, W, B: 1 / (1 + np.exp(np.dot(X, W) + B))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing batch 11/14, eta 0:00:01\n",
            "Covariance matrix is not full rank; solving with SVD (slow)\n",
            "This happened because you have duplicated or too many neurons\n",
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8394\n",
            "Precision: 0.8160\n",
            "Recall: 0.8765\n",
            "F1-Score: 0.8452\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.83      1700\n",
            "           1       0.82      0.88      0.85      1700\n",
            "\n",
            "    accuracy                           0.84      3400\n",
            "   macro avg       0.84      0.84      0.84      3400\n",
            "weighted avg       0.84      0.84      0.84      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from hpelm import HPELM\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define numerical and categorical features\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# One-hot encode the target variable\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))  # For predictions\n",
        "\n",
        "# Initialize HPELM model\n",
        "inputs = X_train_processed.shape[1]  # Number of features\n",
        "outputs = y_train_encoded.shape[1]  # Number of classes\n",
        "model = HPELM(inputs, outputs, classification='c')  # Use 'c' for classification\n",
        "\n",
        "# Add neurons to the model\n",
        "model.add_neurons(3000, 'sigm')  # Add 100 sigmoid neurons, for example\n",
        "\n",
        "# Train model\n",
        "model.train(X_train_processed, y_train_encoded)\n",
        "\n",
        "# Predict using the model\n",
        "y_pred_encoded = model.predict(X_test_processed)\n",
        "\n",
        "# Decode predictions back to original labels\n",
        "y_pred = encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4006ed6e-2aa3-424f-9693-c09f0c9bba1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4006ed6e-2aa3-424f-9693-c09f0c9bba1c",
        "outputId": "39a35868-04e8-42a4-e409-2e44c3e3cdb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class HPELM in module hpelm.hp_elm:\n",
            "\n",
            "class HPELM(hpelm.elm.ELM)\n",
            " |  HPELM(inputs, outputs, classification='', w=None, batch=1000, accelerator=None, precision='double', norm=None, tprint=5)\n",
            " |  \n",
            " |  Interface for training High-Performance Extreme Learning Machines (HP-ELM).\n",
            " |  \n",
            " |  Args:\n",
            " |      inputs (int): dimensionality of input data, or number of data features\n",
            " |      outputs (int): dimensionality of output data, or number of classes\n",
            " |      classification ('c'/'wc'/'ml', optional): train ELM for classfication ('c') / weighted classification ('wc') /\n",
            " |          multi-label classification ('ml'). For weighted classification you can provide weights in `w`. ELM will\n",
            " |          compute and use the corresponding classification error instead of Mean Squared Error.\n",
            " |      w (vector, optional): weights vector for weighted classification, lenght (`outputs` * 1).\n",
            " |      batch (int, optional): batch size for data processing in ELM, reduces memory requirements. Does not work\n",
            " |          for model structure selection (validation, cross-validation, Leave-One-Out). Can be changed later directly\n",
            " |          as a class attribute.\n",
            " |      accelerator (string, optional): type of accelerated ELM to use: None, 'GPU', ...\n",
            " |      precision (optional): data precision to use, supports signle ('single', '32' or numpy.float32) or double\n",
            " |          ('double', '64' or numpy.float64). Single precision is faster but may cause numerical errors. Majority\n",
            " |          of GPUs work in single precision. Default: **double**.\n",
            " |      norm (double, optinal): L2-normalization parameter, **None** gives the default value.\n",
            " |      tprint (int, optional): ELM reports its progess every `tprint` seconds or after every batch,\n",
            " |          whatever takes longer.\n",
            " |  \n",
            " |  Class attributes; attributes that simply store initialization or `train()` parameters are omitted.\n",
            " |  \n",
            " |  Attributes:\n",
            " |      nnet (object): Implementation of neural network with computational methods, but without\n",
            " |          complex logic. Different implementations are given by different classes: for Python, for GPU, etc.\n",
            " |          See ``hpelm.nnets`` folder for particular files. You can implement your own computational algorithm\n",
            " |          by inheriting from ``hpelm.nnets.SLFN`` and overwriting some methods.\n",
            " |      flist (list of strings): Awailable types of neurons, use them when adding new neurons.\n",
            " |  \n",
            " |  Note:\n",
            " |      The 'hdf5' type denotes a name of HDF5 file type with a single 2-dimensional array inside. HPELM uses PyTables\n",
            " |      interface to HDF5: http://www.pytables.org/. For HDF5 array examples, see\n",
            " |      http://www.pytables.org/usersguide/libref/homogenous_storage.html. Array name is irrelevant,\n",
            " |      but there must be **only one array per HDF5 file**.\n",
            " |  \n",
            " |      A 2-dimensional Numpy.ndarray can also be used.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      HPELM\n",
            " |      hpelm.elm.ELM\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  add_data(self, fX, fT, istart=0, icount=inf, fHH=None, fHT=None)\n",
            " |      Feed new training data (X,T) to HP-ELM model in batches: does not solve ELM itself.\n",
            " |      \n",
            " |      This method prepares an intermediate solution data, that takes the most time. After that, obtaining\n",
            " |      the solution is fast.\n",
            " |      \n",
            " |      The intermediate solution consists of two matrices: `HH` and `HT`. They can be in memory for a model computed\n",
            " |      at once, or stored on disk for a model computed in parts or in parallel.\n",
            " |      \n",
            " |      For iterative solution, provide file names for on-disk matrices in the input parameters `fHH` and `fHT`.\n",
            " |      They will be created if they don't exist, or new results will be merged with the existing ones. This method is\n",
            " |      multiprocess-safe for parallel writing into files `fHH` and `fHT`, that allows you to easily compute ELM\n",
            " |      in parallel. The multiprocess-safeness uses Python module 'fasteners' and a lock file, which is named\n",
            " |      fHH+'.lock' and fHT+'.lock'.\n",
            " |      \n",
            " |      Args:\n",
            " |          fX (hdf5): (part of) input training data size (N * `inputs`)\n",
            " |          fT (hdf5) (part of) output training data size (N * `outputs`)\n",
            " |          istart (int, optional): index of first data sample to use from `fX`, `istart` < N. If not given,\n",
            " |              all data from `fX` is used. Sample with index `istart` is used for training, indexing is 0-based.\n",
            " |          icount (int, optional): number of data samples to use from `fX`, starting from `istart`, automatically\n",
            " |              adjusted to `istart` + `icount` <= N. If not given, all data starting from `start` is used.\n",
            " |              The last sample used for training is `istart`+`icount`-1, so you can index data as:\n",
            " |              istart_1=0, icount_1=1000; istart_2=1000, icount_2=1000; istart_3=2000, icount_3=1000, ...\n",
            " |          fHH, fHT (string, optional): file names for storing HH and HT matrices. Files are created if they don't\n",
            " |              exist, or new result is added to the existing files if they exist. Parallel writing to the same\n",
            " |              `fHH`, `fHT` files is multiprocess-safe, made specially for parallel training of HP-ELM. Another use\n",
            " |              is to split a very long training of huge ELM into smaller parts, so the training can be interrupted\n",
            " |              and resumed later.\n",
            " |  \n",
            " |  add_data_async(self, fX, fT, istart=0, icount=inf, fHH=None, fHT=None)\n",
            " |      Version of `add_data()` with asyncronous I/O. See `add_data()` for reference.\n",
            " |      \n",
            " |      Spawns new processes using Python's `multiprocessing` module, and requires more memory than non-async version.\n",
            " |  \n",
            " |  error(self, fT, fY, istart=0, icount=inf)\n",
            " |      Calculate error of model predictions of HPELM.\n",
            " |      \n",
            " |      Computes Mean Squared Error (MSE) between model predictions Y and true outputs T.\n",
            " |      For classification, computes mis-classification error.\n",
            " |      For multi-label classification, correct classes are all with Y>0.5.\n",
            " |      \n",
            " |      For weighted classification the error is an average weighted True Positive Rate,\n",
            " |      or percentage of correctly predicted samples for each class, multiplied by weight\n",
            " |      of that class and averaged. If you want something else, just write it yourself :)\n",
            " |      See https://en.wikipedia.org/wiki/Confusion_matrix for details.\n",
            " |      \n",
            " |      Args:\n",
            " |          fT (hdf5): hdf5 filename with true outputs\n",
            " |          fY (hdf5): hdf5 filename with predicted outputs\n",
            " |          istart (int, optional): index of first data sample to use from `fX`, `istart` < N. If not given,\n",
            " |              all data from `fX` is used. Sample with index `istart` is used for training, indexing is 0-based.\n",
            " |          icount (int, optional): number of data samples to use from `fX`, starting from `istart`, automatically\n",
            " |              adjusted to `istart` + `icount` <= N. If not given, all data starting from `start` is used.\n",
            " |              The last sample used for training is `istart`+`icount`-1, so you can index data as:\n",
            " |              istart_1=0, icount_1=1000; istart_2=1000, icount_2=1000; istart_3=2000, icount_3=1000, ...\n",
            " |      \n",
            " |      Returns:\n",
            " |          e (double): MSE for regression / classification error for classification.\n",
            " |  \n",
            " |  predict(self, fX, fY=None, istart=0, icount=inf)\n",
            " |      Iterative predict outputs and save them to HDF5, can use custom range.\n",
            " |      \n",
            " |      Args:\n",
            " |          fX (hdf5): hdf5 filename or Numpy matrix with input data from which outputs are predicted\n",
            " |          fY (hdf5): hdf5 filename or Numpy matrix to store output data into, if 'None' then Numpy matrix\n",
            " |              is generated automatically.\n",
            " |          istart (int, optional): index of first data sample to use from `fX`, `istart` < N. If not given,\n",
            " |              all data from `fX` is used. Sample with index `istart` is used for training, indexing is 0-based.\n",
            " |          icount (int, optional): number of data samples to use from `fX`, starting from `istart`, automatically\n",
            " |              adjusted to `istart` + `icount` <= N. If not given, all data starting from `start` is used.\n",
            " |              The last sample used for training is `istart`+`icount`-1, so you can index data as:\n",
            " |              istart_1=0, icount_1=1000; istart_2=1000, icount_2=1000; istart_3=2000, icount_3=1000, ...\n",
            " |  \n",
            " |  predict_async(self, fX, fY, istart=0, icount=inf)\n",
            " |      Version of `predict()` with asyncronous I/O. See `predict()` for reference.\n",
            " |      \n",
            " |      Spawns new processes using Python's `multiprocessing` module, and requires more memory than non-async version.\n",
            " |  \n",
            " |  project(self, fX, fH=None, istart=0, icount=inf)\n",
            " |      Iteratively project input data from HDF5 into HPELM hidden layer, and save in another HDF5.\n",
            " |      \n",
            " |      Args:\n",
            " |          fX (hdf5): hdf5 filename or Numpy matrix with input data to project\n",
            " |          fH (hdf5): hdf5 filename or Numpy matrix to store projected inputs, if 'None' then Numpy matrix\n",
            " |              is generated automatically.\n",
            " |          istart (int, optional): index of first data sample to use from `fX`, `istart` < N. If not given,\n",
            " |              all data from `fX` is used. Sample with index `istart` is used for training, indexing is 0-based.\n",
            " |          icount (int, optional): number of data samples to use from `fX`, starting from `istart`, automatically\n",
            " |              adjusted to `istart` + `icount` <= N. If not given, all data starting from `start` is used.\n",
            " |              The last sample used for training is `istart`+`icount`-1, so you can index data as:\n",
            " |              istart_1=0, icount_1=1000; istart_2=1000, icount_2=1000; istart_3=2000, icount_3=1000, ...\n",
            " |  \n",
            " |  solve_corr(self, fHH, fHT)\n",
            " |      Solves an ELM model with the given (covariance) fHH and (correlation) fHT HDF5 files.\n",
            " |      \n",
            " |      Args:\n",
            " |          fHH (hdf5): an hdf5 file with intermediate solution data\n",
            " |          fHT (hdf5): an hdf5 file with intermediate solution data\n",
            " |  \n",
            " |  train(self, fX, fT, *args, **kwargs)\n",
            " |      Universal training interface for HP-ELM model.\n",
            " |      \n",
            " |      Always trains a basic ELM model without model structure selection.\n",
            " |      L2-regularization is available as `norm` parameter at HPELM initialization.\n",
            " |      Number of neurons selection with validation set for trained HPELM is available in `train_hpv()` method.\n",
            " |      \n",
            " |      Args:\n",
            " |          fX (hdf5): input data on disk, size (N * `inputs`)\n",
            " |          fT (hdf5): outputs data on disk, size (N * `outputs`)\n",
            " |          'c'/'wc'/'ml' (string, choose one): train HPELM for classification ('c'), classification with weighted\n",
            " |              classes ('wc') or multi-label classification ('ml') with several correct classes per data sample.\n",
            " |              In classification, number of `outputs` is the number of classes; correct class(es) for each sample\n",
            " |              has value 1 and incorrect classes have 0.\n",
            " |      \n",
            " |      Keyword Args:\n",
            " |          istart (int, optional): index of first data sample to use from `fX`, `istart` < N. If not given,\n",
            " |              all data from `fX` is used. Sample with index `istart` is used for training, indexing is 0-based.\n",
            " |          icount (int, optional): number of data samples to use from `fX`, starting from `istart`, automatically\n",
            " |              adjusted to `istart` + `icount` <= N. If not given, all data starting from `start` is used.\n",
            " |              The last sample used for training is `istart`+`icount`-1, so you can index data as:\n",
            " |              istart_1=0, icount_1=1000; istart_2=1000, icount_2=1000; istart_3=2000, icount_3=1000, ...\n",
            " |          batch (int, optional): batch size for ELM, overwrites batch size from the initialization\n",
            " |  \n",
            " |  train_async(self, fX, fT, *args, **kwargs)\n",
            " |      Training HPELM with asyncronous I/O, good for network drives, etc. See `train()` for reference.\n",
            " |      \n",
            " |      Spawns new processes using Python's `multiprocessing` module.\n",
            " |  \n",
            " |  validation_corr(self, fHH, fHT, fXv, fTv, steps=10)\n",
            " |      Quick batch error evaluation with different numbers of neurons on a validation set.\n",
            " |      \n",
            " |      Only feasible implementation of model structure selection with HP-ELM. This method makes a single pass\n",
            " |      over the validation data, computing errors for all numbers of neurons at once. It requires HDF5 files with\n",
            " |      matrices HH and HT: `fHH` and `fHT`, obtained from `add_data(..., fHH, fHT)` method.\n",
            " |      \n",
            " |      The method writes the best solution to the HPELM model.\n",
            " |      \n",
            " |      Args:\n",
            " |          fHH (string): name of HDF5 file with HH matrix\n",
            " |          fHT (string): name of HDF5 file with HT matrix\n",
            " |          fXv (string): name of HDF5 file with validation dataset inputs\n",
            " |          fTv (string): name of HDF5 file with validation dataset outputs\n",
            " |          steps (int or vector): amount of different numbers of neurons to test, choosen uniformly on a logarithmic\n",
            " |              scale from 3 to number of neurons in HPELM. Can be given exactly as a vector.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Ls (vector): numbers of neurons used by `validation_corr()` method\n",
            " |          errs (vector): corresponding errors for number of neurons in `Ls`, with classification error if model\n",
            " |              is run for classification\n",
            " |          confs (list of matrix): list of confusion matrices corresponding to elements in Ls (empty for regression)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from hpelm.elm.ELM:\n",
            " |  \n",
            " |  __del__(self)\n",
            " |  \n",
            " |  __init__(self, inputs, outputs, classification='', w=None, batch=1000, accelerator=None, precision='double', norm=None, tprint=5)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __str__(self)\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  add_neurons(self, number, func, W=None, B=None)\n",
            " |      Adds neurons to ELM model. ELM is created empty, and needs some neurons to work.\n",
            " |      \n",
            " |      Add neurons to an empty ELM model, or add more neurons to a model that already has some.\n",
            " |      \n",
            " |      Random weights `W` and biases `B` are generated automatically if not provided explicitly.\n",
            " |      Maximum number of neurons is limited by the available RAM and computational power, a sensible limit\n",
            " |      would be 1000 neurons for an average size dataset and 15000 for the largest datasets. ELM becomes slower after\n",
            " |      3000 neurons because computational complexity is proportional to a qube of number of neurons.\n",
            " |      \n",
            " |      This method checks and prepares neurons, they are actually stored in `solver` object.\n",
            " |      \n",
            " |      Args:\n",
            " |          number (int): number of neurons to add\n",
            " |          func (string): type of neurons: \"lin\" for linear, \"sigm\" or \"tanh\" for non-linear,\n",
            " |              \"rbf_l1\", \"rbf_l2\" or \"rbf_linf\" for radial basis function neurons.\n",
            " |          W (matrix, optional): random projection matrix size (`inputs` * `number`). For 'rbf_' neurons,\n",
            " |              W stores centroids of radial basis functions in transposed form.\n",
            " |          B (vector, optional): bias vector of size (`number` * 1), a 1-dimensional Numpy.ndarray object.\n",
            " |              For 'rbf_' neurons, B gives widths of radial basis functions.\n",
            " |  \n",
            " |  confusion(self, T, Y)\n",
            " |      Computes confusion matrix for classification.\n",
            " |      \n",
            " |      Confusion matrix :math:`C` such that element :math:`C_{i,j}` equals to the number of observations known\n",
            " |      to be class :math:`i` but predicted to be class :math:`j`.\n",
            " |      \n",
            " |      Args:\n",
            " |          T (matrix): true outputs or classes, size (N * `outputs`)\n",
            " |          Y (matrix): predicted outputs by ELM model, size (N * `outputs`)\n",
            " |      \n",
            " |      Returns:\n",
            " |          conf (matrix): confusion matrix, size (`outputs` * `outputs`)\n",
            " |  \n",
            " |  load(self, fname)\n",
            " |      Load ELM model data from a file.\n",
            " |      \n",
            " |      Load requires an ``ELM`` object, and it uses solver type, precision and batch size from that ELM object.\n",
            " |      \n",
            " |      Args:\n",
            " |          fname (string): filename to load model from.\n",
            " |  \n",
            " |  save(self, fname)\n",
            " |      Save ELM model with current parameters.\n",
            " |      \n",
            " |      Model does not save a particular solver, precision batch size. They are obtained from\n",
            " |      a new ELM when loading the model (so one can switch to another solver, for instance).\n",
            " |      \n",
            " |      Also ranking and max number of neurons are not saved, because they\n",
            " |      are runtime training info irrelevant after the training completes.\n",
            " |      \n",
            " |      Args:\n",
            " |          fname (string): filename to save model into.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from hpelm.elm.ELM:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(HPELM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fadc4ca-1a57-4b76-b29a-f57d6285869e",
      "metadata": {
        "id": "7fadc4ca-1a57-4b76-b29a-f57d6285869e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01p3PWZwYSiy"
      },
      "id": "01p3PWZwYSiy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMNfuRZCYSf-"
      },
      "id": "LMNfuRZCYSf-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6cMaaL_cc_WO"
      },
      "id": "6cMaaL_cc_WO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ig2-gnhKc_RW"
      },
      "id": "ig2-gnhKc_RW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRS3lor5c_Ow"
      },
      "id": "NRS3lor5c_Ow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized Bagging Ensamble"
      ],
      "metadata": {
        "id": "xMQnlf_HdAtw"
      },
      "id": "xMQnlf_HdAtw"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define numerical and categorical features\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the Bagging model with specified parameters\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(\n",
        "        min_samples_split=10,\n",
        "        max_depth=None,\n",
        "        random_state=42  # Add random_state for reproducibility\n",
        "    ),\n",
        "    n_estimators=100,\n",
        "    max_features=0.5,\n",
        "    max_samples=0.8,\n",
        "    random_state=42  # Add random_state for reproducibility\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "bagging_model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DvR9cEqc_ML",
        "outputId": "1ada0b44-08dc-4a28-df5b-c3899cba7b28"
      },
      "id": "5DvR9cEqc_ML",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.9074\n",
            "Precision: 0.8924\n",
            "Recall: 0.9265\n",
            "F1-Score: 0.9091\n",
            "ROC-AUC: 0.9074\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91      1700\n",
            "           1       0.89      0.93      0.91      1700\n",
            "\n",
            "    accuracy                           0.91      3400\n",
            "   macro avg       0.91      0.91      0.91      3400\n",
            "weighted avg       0.91      0.91      0.91      3400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HCFtGtbhc_Jo"
      },
      "id": "HCFtGtbhc_Jo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ZONj7uxc_HL"
      },
      "id": "6ZONj7uxc_HL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6imYBmSDc_Ep"
      },
      "id": "6imYBmSDc_Ep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lbmlAOmvc_CW"
      },
      "id": "lbmlAOmvc_CW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ndtakwdmc-_6"
      },
      "id": "ndtakwdmc-_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNDmWB-Mc-9r"
      },
      "id": "hNDmWB-Mc-9r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvvLcKwCc-4_"
      },
      "id": "QvvLcKwCc-4_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iw_1GS6BYSHb"
      },
      "id": "Iw_1GS6BYSHb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ignore Logistic Regression, Random Forest Classifier, Support Vector Machines and K-Nearest Neighbourh\n",
        "\n",
        "## When the stand individually, they don't work so well."
      ],
      "metadata": {
        "id": "d6jQpNEOYWeH"
      },
      "id": "d6jQpNEOYWeH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a710b74-ec4e-4971-b43c-a67f442a6451",
      "metadata": {
        "id": "0a710b74-ec4e-4971-b43c-a67f442a6451"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81d3ea6-7eae-407c-86e3-fbaaceb00fb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f81d3ea6-7eae-407c-86e3-fbaaceb00fb5",
        "outputId": "2762ffda-f781-485f-80ac-6ef629876857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8779\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8724\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(random_state=42, max_iter=500, solver='saga', C=0.1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e731a829-7f87-433f-a823-80ebbedad735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e731a829-7f87-433f-a823-80ebbedad735",
        "outputId": "701fcb38-5a16-4e65-ddc9-005461f7a52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8779\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8724\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(random_state=42, max_iter=500, solver='lbfgs', C=0.1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff1b3ad-f20f-4601-ab61-38e7b7a58189",
      "metadata": {
        "id": "1ff1b3ad-f20f-4601-ab61-38e7b7a58189"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9970db3a-f9e8-4c39-8e89-db6017343495",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9970db3a-f9e8-4c39-8e89-db6017343495",
        "outputId": "e49e7036-5b22-43ee-d8ac-aadbcd21ea41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.1, 'max_iter': 200, 'solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {\n",
        "    'solver': ['lbfgs', 'saga'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'max_iter': [100, 200, 500]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=LogisticRegression(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Use appropriate scoring metric\n",
        "    cv=5  # Number of folds in cross-validation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00ead63b-3b8b-4a91-b751-2df95ea1b7e4",
      "metadata": {
        "id": "00ead63b-3b8b-4a91-b751-2df95ea1b7e4"
      },
      "outputs": [],
      "source": [
        "# help(GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa4e7e3-bcbf-4813-a01c-f3501d51d7f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fa4e7e3-bcbf-4813-a01c-f3501d51d7f4",
        "outputId": "38166a09-91c2-4b69-b696-0bf7d738c628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8779\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8724\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize Logistic Regression model with the tuned parameters\n",
        "model = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=100,\n",
        "    solver='saga',\n",
        "    C=0.1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa9b3efd-2ebc-44bc-91ac-8880ee0f9968",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa9b3efd-2ebc-44bc-91ac-8880ee0f9968",
        "outputId": "132e457a-d07f-4757-dd27-fe5c2469460e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics\n",
            "=====================================\n",
            "Accuracy: 0.8724\n",
            "Precision: 0.8777\n",
            "Recall: 0.8653\n",
            "F1-Score: 0.8714\n",
            "ROC-AUC: 0.8724\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Regularized Logistic Regression model\n",
        "# L1 Regularization (lasso): `penalty='l1'`\n",
        "# L2 Regularization (ridge): `penalty='l2'`\n",
        "model = LogisticRegression(\n",
        "    random_state=42,\n",
        "    solver='saga',\n",
        "    C=0.1,  # Regularization strength\n",
        "    penalty='l1'  # Use L1 or L2\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics\")\n",
        "print(\"=====================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c58093-1423-4acb-93a7-148b55448fe7",
      "metadata": {
        "id": "b9c58093-1423-4acb-93a7-148b55448fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067d05d6-645e-406f-dc8f-484ab265674d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Best Cross-Validation Accuracy: 0.8866911764705883\n",
            "Evaluation Metrics for Best Model\n",
            "=====================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8761\n",
            "Recall: 0.8694\n",
            "F1-Score: 0.8727\n",
            "ROC-AUC: 0.8732\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the parameter grid for regularization strength\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Values to test for regularization strength\n",
        "    'solver': ['saga'],  # Saga supports both L1 and L2 regularization\n",
        "    'penalty': ['l1', 'l2']  # Test both L1 (Lasso) and L2 (Ridge)\n",
        "}\n",
        "\n",
        "# Grid search for best regularization strength\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=500),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # You can switch to precision, recall, or other metrics\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Print the best parameters and corresponding score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model for evaluation on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the best model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics for Best Model\")\n",
        "print(\"=====================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f353c6-f0da-4b56-b75f-5c2a1f19985a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0f353c6-f0da-4b56-b75f-5c2a1f19985a",
        "outputId": "4db898d3-379d-4e26-a66a-896d296eb811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 0.01, 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
            "Best Cross-Validation Accuracy: 0.8857352941176471\n",
            "\n",
            "Evaluation Metrics for ElasticNet Regularization\n",
            "====================================================\n",
            "Accuracy: 0.8712\n",
            "Precision: 0.8760\n",
            "Recall: 0.8647\n",
            "F1-Score: 0.8703\n",
            "ROC-AUC: 0.8712\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the parameter grid for ElasticNet regularization\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization strengths\n",
        "    'l1_ratio': [0.2, 0.5, 0.8],  # Mix of L1 and L2 penalties\n",
        "    'solver': ['saga'],  # Saga supports ElasticNet\n",
        "    'penalty': ['elasticnet']  # Use ElasticNet penalty\n",
        "}\n",
        "\n",
        "# Grid search to find the best ElasticNet parameters\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=500),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # You can also use precision, recall, etc.\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Print the best parameters and corresponding score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model for evaluation on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the best model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics for ElasticNet Regularization\")\n",
        "print(\"====================================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9920dd7-e1e1-4507-b45b-00d838e772f0",
      "metadata": {
        "id": "a9920dd7-e1e1-4507-b45b-00d838e772f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c913bcca-2e27-40dd-ad44-0dee24a36975",
      "metadata": {
        "id": "c913bcca-2e27-40dd-ad44-0dee24a36975"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3862eb-82b6-40a8-94f5-4737584cac1a",
      "metadata": {
        "id": "fc3862eb-82b6-40a8-94f5-4737584cac1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a604a851-3297-48db-a9b9-6c3e6cb15ed6",
      "metadata": {
        "id": "a604a851-3297-48db-a9b9-6c3e6cb15ed6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2015041-410e-44c7-8f12-1d6dd9f7f2c6",
      "metadata": {
        "id": "d2015041-410e-44c7-8f12-1d6dd9f7f2c6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9dc64cb-943e-4c1b-ba8a-3ffddf25ef6c",
      "metadata": {
        "id": "e9dc64cb-943e-4c1b-ba8a-3ffddf25ef6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89395c3-f6f5-4f5e-9593-987bd2b2ddc1",
      "metadata": {
        "id": "e89395c3-f6f5-4f5e-9593-987bd2b2ddc1"
      },
      "outputs": [],
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc3002c-9368-4220-a1e1-26d4bf9438be",
      "metadata": {
        "id": "5bc3002c-9368-4220-a1e1-26d4bf9438be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a6223b-fa5f-4489-f27b-629bc49f9c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.9021\n",
            "Precision: 0.8926\n",
            "Recall: 0.9141\n",
            "F1-Score: 0.9032\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      1700\n",
            "           1       0.89      0.91      0.90      1700\n",
            "\n",
            "    accuracy                           0.90      3400\n",
            "   macro avg       0.90      0.90      0.90      3400\n",
            "weighted avg       0.90      0.90      0.90      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=2500, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747c557c-e2b6-4bca-a5b7-a923011c3f54",
      "metadata": {
        "id": "747c557c-e2b6-4bca-a5b7-a923011c3f54"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2535d06b-b704-497a-97a1-e1a2e721e6b4",
      "metadata": {
        "id": "2535d06b-b704-497a-97a1-e1a2e721e6b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d8c89d-add6-4066-b854-c7f6999b3492",
      "metadata": {
        "id": "20d8c89d-add6-4066-b854-c7f6999b3492"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machine(SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9620f191-1513-4b19-b975-6d8a05be4e3c",
      "metadata": {
        "id": "9620f191-1513-4b19-b975-6d8a05be4e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad87c23-650b-4b38-aef5-5be1d3200528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8803\n",
            "Precision: 0.8761\n",
            "Recall: 0.8859\n",
            "F1-Score: 0.8810\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88      1700\n",
            "           1       0.88      0.89      0.88      1700\n",
            "\n",
            "    accuracy                           0.88      3400\n",
            "   macro avg       0.88      0.88      0.88      3400\n",
            "weighted avg       0.88      0.88      0.88      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize SVM model\n",
        "model = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374e97b4-2200-4c73-ba18-900c7859f5bf",
      "metadata": {
        "id": "374e97b4-2200-4c73-ba18-900c7859f5bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6065a4c-f46a-46c7-9eff-5e0aa3ff6a32",
      "metadata": {
        "id": "a6065a4c-f46a-46c7-9eff-5e0aa3ff6a32"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312b82e9-dd3b-4d2a-b267-2333176f2126",
      "metadata": {
        "id": "312b82e9-dd3b-4d2a-b267-2333176f2126"
      },
      "outputs": [],
      "source": [
        "# K-Nearest Neighbourh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5439170-6fef-4e0a-9b4e-ea8e62e45a04",
      "metadata": {
        "id": "f5439170-6fef-4e0a-9b4e-ea8e62e45a04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f688239-1ee3-4d10-c0b7-d9ad0984a433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8679\n",
            "Precision: 0.8564\n",
            "Recall: 0.8841\n",
            "F1-Score: 0.8700\n",
            "ROC-AUC: 0.8998\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87      1700\n",
            "           1       0.86      0.88      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize KNN model\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3fd1412-5de3-4504-9b96-d6080b7c86af",
      "metadata": {
        "id": "d3fd1412-5de3-4504-9b96-d6080b7c86af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5246d9-51ee-411c-a035-56d4a5af1232",
      "metadata": {
        "id": "de5246d9-51ee-411c-a035-56d4a5af1232"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tuZ2_qcvZJ3K"
      },
      "id": "tuZ2_qcvZJ3K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Ensemble Models"
      ],
      "metadata": {
        "id": "RYMwswgnZNGN"
      },
      "id": "RYMwswgnZNGN"
    },
    {
      "cell_type": "markdown",
      "id": "9aa1caac-0ce3-424b-b2d3-000caed7e360",
      "metadata": {
        "id": "9aa1caac-0ce3-424b-b2d3-000caed7e360"
      },
      "source": [
        "# Voting Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79e4965-57e6-4746-af78-48f1f0bec0d7",
      "metadata": {
        "id": "f79e4965-57e6-4746-af78-48f1f0bec0d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba048c9e-3615-49d6-9dba-9d8ce34c7637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Ensemble Metrics\n",
            "=================================\n",
            "Accuracy: 0.8888\n",
            "Precision: 0.8865\n",
            "Recall: 0.8918\n",
            "F1-Score: 0.8891\n",
            "ROC-AUC: 0.8888\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize individual models\n",
        "log_reg = LogisticRegression(random_state=42, C=0.01, penalty='l2', solver='saga', max_iter=500)  # Best-tuned LR model\n",
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=100)  # Random Forest\n",
        "svm_clf = SVC(probability=True, random_state=42)  # Support Vector Machine with probability for soft voting\n",
        "\n",
        "# Create the VotingClassifier (use 'soft' or 'hard' voting)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_reg), ('rf', rf_clf), ('svm', svm_clf)],\n",
        "    voting='soft'  # For soft voting based on probabilities\n",
        ")\n",
        "\n",
        "# Train the ensemble model\n",
        "voting_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_clf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Voting Ensemble Metrics\")\n",
        "print(\"=================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7841555-1e8e-4383-8e98-9d15faad3b06",
      "metadata": {
        "id": "c7841555-1e8e-4383-8e98-9d15faad3b06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89dcdda-4b8a-4bc3-ac72-c508ab3f99c0",
      "metadata": {
        "id": "e89dcdda-4b8a-4bc3-ac72-c508ab3f99c0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0a7541f8-6a7f-4562-93c9-e347ec867d6b",
      "metadata": {
        "id": "0a7541f8-6a7f-4562-93c9-e347ec867d6b"
      },
      "source": [
        "# Stacking Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23f6c8b-ac15-4cf7-beec-5b1d3039d3f7",
      "metadata": {
        "id": "e23f6c8b-ac15-4cf7-beec-5b1d3039d3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8cfbb3-fb06-43d5-c26e-bb9870266d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Ensemble Metrics\n",
            "=================================\n",
            "Accuracy: 0.8974\n",
            "Precision: 0.8907\n",
            "Recall: 0.9059\n",
            "F1-Score: 0.8982\n",
            "ROC-AUC: 0.8974\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),  # Random Forest\n",
        "    ('svm', SVC(probability=True, random_state=42))  # Support Vector Machine with probability output\n",
        "]\n",
        "\n",
        "# Define the meta-model (Logistic Regression in this case)\n",
        "meta_model = LogisticRegression(random_state=42, solver='saga', C=0.1, penalty='l2')\n",
        "\n",
        "# Create the StackingClassifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5  # Cross-validation during training of the meta-model\n",
        ")\n",
        "\n",
        "# Train the Stacking Ensemble\n",
        "stacking_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = stacking_clf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the Stacking Ensemble\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Stacking Ensemble Metrics\")\n",
        "print(\"=================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff81a593-a81a-47b6-8c12-809b708eb0d1",
      "metadata": {
        "id": "ff81a593-a81a-47b6-8c12-809b708eb0d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "02719a1a-e10c-47ca-ab78-da8e41cb7fbe",
      "metadata": {
        "id": "02719a1a-e10c-47ca-ab78-da8e41cb7fbe"
      },
      "source": [
        "## Tuning the Base Models and Meta-Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625e9b65-509c-44d8-a4a0-249267ddef12",
      "metadata": {
        "id": "625e9b65-509c-44d8-a4a0-249267ddef12"
      },
      "source": [
        "### Step 1: Tune the Base Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399a63f3-0503-4d5a-9af1-8578fc28c794",
      "metadata": {
        "id": "399a63f3-0503-4d5a-9af1-8578fc28c794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a40099-4a64-4115-b089-eb7f845e4958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Parameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Best SVM Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Tuning Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees\n",
        "    'max_depth': [10, 20, None],     # Maximum depth of trees\n",
        "    'min_samples_split': [2, 5, 10]  # Minimum samples to split a node\n",
        "}\n",
        "\n",
        "rf_search = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid=rf_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "rf_search.fit(X_train_processed, y_train)\n",
        "best_rf = rf_search.best_estimator_\n",
        "print(\"Best Random Forest Parameters:\", rf_search.best_params_)\n",
        "\n",
        "# Tuning SVM\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10],           # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
        "    'gamma': ['scale', 'auto']    # Kernel coefficient\n",
        "}\n",
        "\n",
        "svm_search = GridSearchCV(\n",
        "    SVC(probability=True, random_state=42),\n",
        "    param_grid=svm_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "svm_search.fit(X_train_processed, y_train)\n",
        "best_svm = svm_search.best_estimator_\n",
        "print(\"Best SVM Parameters:\", svm_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2664cb8b-9fcf-41f4-91e0-fd3264fbb4ac",
      "metadata": {
        "id": "2664cb8b-9fcf-41f4-91e0-fd3264fbb4ac"
      },
      "source": [
        "### Step 2: Tune the Meta-Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a33dab-30be-4df6-a379-2c2407b60c33",
      "metadata": {
        "id": "31a33dab-30be-4df6-a379-2c2407b60c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d5008e-9b1c-4da3-ee6d-e31f53aa3c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Tuning Logistic Regression (meta-model)\n",
        "lr_param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
        "    'solver': ['saga'],       # Solver for ElasticNet\n",
        "    'penalty': ['l1', 'l2']   # Regularization type\n",
        "}\n",
        "\n",
        "lr_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=500),\n",
        "    param_grid=lr_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "lr_search.fit(X_train_processed, y_train)\n",
        "best_meta_model = lr_search.best_estimator_\n",
        "print(\"Best Logistic Regression Parameters:\", lr_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66228d97-567e-486f-9641-66bd6910483c",
      "metadata": {
        "id": "66228d97-567e-486f-9641-66bd6910483c"
      },
      "source": [
        "### Step 3: Integrate Tuned Models into Stacking Ensemble\n",
        "Finally, use the tuned base models (best_rf, best_svm) and the meta-model (best_meta_model) in the stacking classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3955e299-15ed-4d80-8c79-4fb1d89a4cb7",
      "metadata": {
        "id": "3955e299-15ed-4d80-8c79-4fb1d89a4cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6981e2-4da2-41bf-9775-d273b19b2f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized Stacking Ensemble Metrics\n",
            "======================================\n",
            "Accuracy: 0.9000\n",
            "Precision: 0.8981\n",
            "Recall: 0.9024\n",
            "F1-Score: 0.9002\n",
            "ROC-AUC: 0.9000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Define tuned models\n",
        "base_models = [\n",
        "    ('rf', best_rf),\n",
        "    ('svm', best_svm)\n",
        "]\n",
        "\n",
        "# Stacking classifier with tuned models\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=best_meta_model,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Train the optimized Stacking Ensemble\n",
        "stacking_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Evaluate the ensemble\n",
        "y_pred = stacking_clf.predict(X_test_processed)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nOptimized Stacking Ensemble Metrics\")\n",
        "print(\"======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7a7eaa-c0a2-4243-aac2-3434f32b7cdc",
      "metadata": {
        "id": "2f7a7eaa-c0a2-4243-aac2-3434f32b7cdc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97058ee5-0442-4cf5-8783-4547ed66a44f",
      "metadata": {
        "id": "97058ee5-0442-4cf5-8783-4547ed66a44f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f797821-63bb-40b0-b705-09c198c3b180",
      "metadata": {
        "id": "6f797821-63bb-40b0-b705-09c198c3b180"
      },
      "source": [
        "# Bagging Ensemble Model\n",
        "Bagging, short for Bootstrap Aggregating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05cd957b-a65b-464e-bb9b-a49fc386250a",
      "metadata": {
        "id": "05cd957b-a65b-464e-bb9b-a49fc386250a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd23580-f1ed-4713-93e5-c8de7d17e718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bagging Ensemble Metrics\n",
            "=======================================\n",
            "Accuracy: 0.8976\n",
            "Precision: 0.8890\n",
            "Recall: 0.9088\n",
            "F1-Score: 0.8988\n",
            "ROC-AUC: 0.8976\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize base model (Decision Tree in this case)\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Create BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_model,  # Correct keyword for base model\n",
        "    n_estimators=50,       # Number of base models\n",
        "    max_samples=0.8,       # Fraction of samples used for training each base model\n",
        "    max_features=0.8,      # Fraction of features used for training each base model\n",
        "    bootstrap=True,        # Enable bootstrapping of samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the Bagging model\n",
        "bagging_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_clf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the Bagging model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nBagging Ensemble Metrics\")\n",
        "print(\"=======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86e8f79-e819-4b8b-bc53-a35a8f17bcf2",
      "metadata": {
        "id": "b86e8f79-e819-4b8b-bc53-a35a8f17bcf2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f676a889-d27d-4b67-888d-20590758d8c3",
      "metadata": {
        "id": "f676a889-d27d-4b67-888d-20590758d8c3"
      },
      "source": [
        "## hyperparameter Tuning for Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4324f710-67fc-47b8-83cc-e01cdd1d3817",
      "metadata": {
        "id": "4324f710-67fc-47b8-83cc-e01cdd1d3817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57110751-2cf5-4d42-d43a-1e060001964a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'estimator__max_depth': None, 'estimator__min_samples_split': 10, 'max_features': 0.5, 'max_samples': 0.8, 'n_estimators': 100}\n",
            "Best Cross-Validation Accuracy: 0.9098529411764705\n",
            "\n",
            "Optimized Bagging Ensemble Metrics\n",
            "=======================================\n",
            "Accuracy: 0.9074\n",
            "Precision: 0.8924\n",
            "Recall: 0.9265\n",
            "F1-Score: 0.9091\n",
            "ROC-AUC: 0.9074\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ===== Beginning of Added =====#\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define numerical and categorical features\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# ===== End of Added =====#\n",
        "\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the Bagging model with a Decision Tree as the base estimator\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid for Bagging\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],  # Number of estimators\n",
        "    'max_samples': [0.5, 0.8, 1.0],  # Fraction of training samples for each base estimator\n",
        "    'max_features': [0.5, 0.8, 1.0],  # Fraction of features for each base estimator\n",
        "    'estimator__max_depth': [3, 5, None],  # Max depth of the base Decision Tree\n",
        "    'estimator__min_samples_split': [2, 5, 10]  # Min samples to split a node\n",
        "}\n",
        "\n",
        "# GridSearchCV for BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_model,\n",
        "    bootstrap=True,  # Bootstrap samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=bagging_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Evaluate using accuracy\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "# Fit the grid search on the training data\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_bagging_clf = grid_search.best_estimator_\n",
        "y_pred = best_bagging_clf.predict(X_test_processed)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nOptimized Bagging Ensemble Metrics\")\n",
        "print(\"=======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "USV9q6aGGOvr"
      },
      "id": "USV9q6aGGOvr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0egO4GgGPlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f979fe4-86d1-4e51-d185-d0acd4f151ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'estimator__max_depth': None, 'estimator__min_samples_split': 25, 'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 1000}\n",
            "Best Cross-Validation Accuracy: 0.9130882352941176\n",
            "\n",
            "Optimized Bagging Ensemble Metrics\n",
            "=======================================\n",
            "Accuracy: 0.9106\n",
            "Precision: 0.9011\n",
            "Recall: 0.9224\n",
            "F1-Score: 0.9116\n",
            "ROC-AUC: 0.9106\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ===== Beginning of Added =====#\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define numerical and categorical features\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# ===== End of Added =====#\n",
        "\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the Bagging model with a Decision Tree as the base estimator\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid for Bagging\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 1000],  # Number of estimators\n",
        "    'max_samples': [0.5, 0.8, 1.0],  # Fraction of training samples for each base estimator\n",
        "    'max_features': [0.5, 0.8, 1.0],  # Fraction of features for each base estimator\n",
        "    'estimator__max_depth': [3, 5, None],  # Max depth of the base Decision Tree\n",
        "    'estimator__min_samples_split': [2, 5, 10, 15, 20, 25]  # Min samples to split a node\n",
        "}\n",
        "\n",
        "# GridSearchCV for BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_model,\n",
        "    bootstrap=True,  # Bootstrap samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=bagging_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Evaluate using accuracy\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "# Fit the grid search on the training data\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_bagging_clf = grid_search.best_estimator_\n",
        "y_pred = best_bagging_clf.predict(X_test_processed)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nOptimized Bagging Ensemble Metrics\")\n",
        "print(\"=======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ],
      "id": "H0egO4GgGPlG"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ===== Beginning of Added =====#\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define numerical and categorical features\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# ===== End of Added =====#\n",
        "\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the Bagging model with a Decision Tree as the base estimator\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid for Bagging\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 1000],  # Number of estimators\n",
        "    'max_samples': [0.5, 0.8, 1.0],  # Fraction of training samples for each base estimator\n",
        "    'max_features': [0.5, 0.8, 1.0],  # Fraction of features for each base estimator\n",
        "    'estimator__max_depth': [3, 5, None],  # Max depth of the base Decision Tree\n",
        "    'estimator__min_samples_split': [2, 5, 10, 15, 20, 25, 40, 50, 60, 70, 100]  # Min samples to split a node\n",
        "}\n",
        "\n",
        "# GridSearchCV for BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_model,\n",
        "    bootstrap=True,  # Bootstrap samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=bagging_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Evaluate using accuracy\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "# Fit the grid search on the training data\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_bagging_clf = grid_search.best_estimator_\n",
        "y_pred = best_bagging_clf.predict(X_test_processed)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nOptimized Bagging Ensemble Metrics\")\n",
        "print(\"=======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "d14ZUxL3CuEH"
      },
      "id": "d14ZUxL3CuEH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We're Choosing the Hyperparameter Tuned Or Optimized Bagging Ensemble Model"
      ],
      "metadata": {
        "id": "Ca7SyqVxkn7J"
      },
      "id": "Ca7SyqVxkn7J"
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have already trained and evaluated the models, and have the following metrics stored:\n",
        "# For XGBoost_1:\n",
        "accuracy_xgb1 = 0.9091\n",
        "precision_xgb1 = 0.9009\n",
        "recall_xgb1 = 0.9194\n",
        "f1_xgb1 = 0.9100\n",
        "roc_auc_xgb1 = 0.9766\n",
        "\n",
        "# For Optimized Bagging Ensemble:\n",
        "accuracy_bagging =  0.9074 # Replace with your actual value #accuracy = accuracy_score(y_test, y_pred)\n",
        "precision_bagging = 0.8924  # Replace with your actual value  #precision = precision_score(y_test, y_pred)\n",
        "recall_bagging = 0.9265  # Replace with your actual value #recall = recall_score(y_test, y_pred)\n",
        "f1_bagging = 0.9091  # Replace with your actual value #f1 = f1_score(y_test, y_pred)\n",
        "roc_auc_bagging = 0.9074  # Replace with your actual value #roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Create a list of models and their metrics\n",
        "models = ['XGBoost_1', 'Optimized Bagging']\n",
        "accuracy = [accuracy_xgb1, accuracy_bagging]\n",
        "precision = [precision_xgb1, precision_bagging]\n",
        "recall = [recall_xgb1, recall_bagging]\n",
        "f1 = [f1_xgb1, f1_bagging]\n",
        "roc_auc = [roc_auc_xgb1, roc_auc_bagging]\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.15  # Reduced bar width for spacing\n",
        "\n",
        "# Set the positions of the bars on the x-axis\n",
        "index = np.arange(len(models))\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.bar(index, accuracy, bar_width, label='Accuracy')\n",
        "plt.bar(index + bar_width, precision, bar_width, label='Precision')\n",
        "plt.bar(index + 2 * bar_width, recall, bar_width, label='Recall')\n",
        "plt.bar(index + 3 * bar_width, f1, bar_width, label='F1-Score')\n",
        "plt.bar(index + 4 * bar_width, roc_auc, bar_width, label='ROC-AUC')\n",
        "\n",
        "# Add value labels on top of bars\n",
        "for i, v in enumerate(accuracy):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "for i, v in enumerate(precision):\n",
        "    plt.text(i + bar_width, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "for i, v in enumerate(recall):\n",
        "    plt.text(i + 2 * bar_width, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "for i, v in enumerate(f1):\n",
        "    plt.text(i + 3 * bar_width, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "for i, v in enumerate(roc_auc):\n",
        "    plt.text(i + 4 * bar_width, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "\n",
        "# Add labels, title, and legend\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(index + 2 * bar_width, models)  # Center the x-axis labels\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # Move legend outside\n",
        "\n",
        "# Display the chart\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "OdbqDVp8zx7j",
        "outputId": "7542005c-9ec1-469c-ae92-2b16bb1bb47b"
      },
      "id": "OdbqDVp8zx7j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Choose XGBoost_1 Over the Optimized Bagging Ensemble?\n",
        "\n",
        "### **Performance Metrics Comparison**\n",
        "| Metric            | Optimized Bagging Ensemble | XGBoost_1        |\n",
        "|--------------------|----------------------------|------------------|\n",
        "| **Accuracy**       | 90.74%                     | **90.91%**       |\n",
        "| **Precision**      | 89.24%                     | **90.09%**       |\n",
        "| **Recall**         | **92.65%**                 | 91.94%           |\n",
        "| **F1-Score**       | 90.91%                     | **91.00%**       |\n",
        "| **ROC-AUC**        | 90.74%                     | **97.66%**       |\n",
        "\n",
        "---\n",
        "\n",
        "### **Why XGBoost_1 is Preferred**\n",
        "1. **Higher Overall Performance**:\n",
        "   - XGBoost_1 outperforms the Bagging Ensemble in key metrics such as **Accuracy (90.91%)**, **Precision (90.09%)**, and **F1-Score (91.00%)**, making it a well-rounded choice for diabetic diagnosis.\n",
        "\n",
        "2. **Superior ROC-AUC**:\n",
        "   - With a **ROC-AUC of 97.66%**, XGBoost_1 demonstrates significantly better capability to distinguish between diabetic and non-diabetic cases across various decision thresholds.\n",
        "\n",
        "3. **Balanced Precision and Recall**:\n",
        "   - XGBoost_1 achieves a balance between **Precision** and **Recall**, minimizing both false positives and false negatives. This is critical for medical applications where both overdiagnosis and underdiagnosis can have serious consequences.\n",
        "\n",
        "---\n",
        "\n",
        "### **When to Consider the Bagging Ensemble**\n",
        "- The **Optimized Bagging Ensemble** has a higher **Recall (92.65%)** compared to XGBoost_1 (91.94%). If identifying every diabetic patient is the absolute priorityat the cost of slightly more false positivesthen the Bagging model might be more suitable.\n",
        "\n",
        "---\n",
        "\n",
        "### **Final Recommendation**\n",
        "- **XGBoost_1** is the preferred model due to its superior balance of metrics, particularly its high **ROC-AUC**, which ensures exceptional diagnostic reliability. It is the better choice for a diabetic diagnosis scenario where both precision and recall are crucial.\n"
      ],
      "metadata": {
        "id": "-7ZtUkJa3zrA"
      },
      "id": "-7ZtUkJa3zrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1596b66-8c12-4615-9ad1-19365d0911f3",
      "metadata": {
        "id": "b1596b66-8c12-4615-9ad1-19365d0911f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c7a5be1-79e7-403d-98fa-aebc9afdac92",
      "metadata": {
        "id": "5c7a5be1-79e7-403d-98fa-aebc9afdac92"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d32ce40-8b2e-4d66-8683-efc1c6f94f8c",
      "metadata": {
        "id": "8d32ce40-8b2e-4d66-8683-efc1c6f94f8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Research Paper\n",
        "\n",
        "\n",
        "# Classification-Based Algorithm for Diabetes Diagnosis\n",
        "\n",
        "## Abstract\n",
        "Diabetes mellitus, particularly Type 2 diabetes, represents a significant global health concern, requiring accurate and timely diagnostics. Traditional diagnostic methods often fall short due to cost, time, and error rates. This study leverages machine learning models, including XGBoost and an optimized Bagging Ensemble, to address class imbalance and enhance the predictive accuracy for diabetes diagnosis. By preprocessing a clinical dataset containing 100K samples, balancing it, and evaluating performance metrics, our models achieve precision and recall suitable for automated healthcare applications. Among several approaches tested, XGBoost_1 and the optimized Bagging Ensemble emerge as the most promising tools for diabetes prediction. This paper documents the methodology, challenges faced during data preparation, and the comparative analysis of machine learning models to identify the best classifiers.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction\n",
        "Diabetes mellitus is a chronic condition impacting millions worldwide, demanding innovative approaches for early detection and diagnosis. While traditional methods are effective, they are often resource-intensive and prone to errors, limiting their scalability. Machine learning provides a promising alternative to improve diagnostic accuracy and efficiency, particularly for Type 2 diabetes.\n",
        "\n",
        "This research explores the application of advanced machine learning techniques to build a classification-based model for Type 2 diabetes diagnosis. Key challenges, such as dataset imbalance and model overfitting, are addressed using novel preprocessing techniques, undersampling strategies, and algorithmic innovations. This study focuses on optimizing models for accuracy, precision, recall, and F1-score to deliver a scalable diagnostic tool suitable for diverse healthcare settings.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Methodology\n",
        "\n",
        "### 2.1 Dataset Collection and Preprocessing\n",
        "The dataset used in this study was sourced from Kaggle, containing 100,000 samples of patients' clinical data. The key features included:\n",
        "- Demographic attributes: Gender, age.\n",
        "- Clinical attributes: Hypertension, heart disease, smoking history, BMI, HbA1c level, blood glucose level.\n",
        "- Target variable: Diabetes (binary classification).\n",
        "\n",
        "#### Initial Cleaning\n",
        "- Unnecessary features such as location, race attributes, clinical notes, year, and inferred diabetes type were removed.\n",
        "- The dataset was analyzed to confirm its focus on Type 2 diabetes using clinical notes. Samples with unclear or irrelevant diabetes classification were excluded.\n",
        "\n",
        "#### Handling Imbalanced Data\n",
        "- The original dataset contained a 10.76:1 imbalance ratio with 91,500 non-diabetic samples and 8,500 diabetic samples. This imbalance was addressed using two techniques:\n",
        "  1. **SMOTE (Synthetic Minority Oversampling Technique)**: Used initially to explore the impact of oversampling.\n",
        "  2. **Balancing via Sampling**: Non-diabetic samples were randomly undersampled to match diabetic samples, resulting in a balanced dataset of 17,000 samples (8,500 diabetic, 8,500 non-diabetic).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2 Model Development\n",
        "Two key models emerged as the best performers:\n",
        "1. **XGBoost_1**:\n",
        "   - Built using Extreme Gradient Boosting (XGBoost) with optimized hyperparameters.\n",
        "   - Threshold: 0.5.\n",
        "   - Features were preprocessed using standard scaling and Adaptive Synthetic Sampling (ADASYN).\n",
        "   - Achieved high recall and balanced performance across precision and F1-score.\n",
        "\n",
        "2. **Optimized Bagging Ensemble**:\n",
        "   - Developed using Bagging techniques, leveraging multiple weak learners (decision trees).\n",
        "   - Hyperparameter tuning improved robustness and generalization.\n",
        "   - Also addressed imbalanced data with preprocessing strategies.\n",
        "\n",
        "Other models, such as HPELM, were developed but did not achieve comparable performance metrics.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Results\n",
        "\n",
        "### XGBoost Model Comparison\n",
        "Pre-SMOTE and Hybrid SMOTE models were tested using the unbalanced dataset:\n",
        "| Metric             | Pre-SMOTE         | Hybrid SMOTE     |\n",
        "|---------------------|-------------------|------------------|\n",
        "| **Accuracy**        | 97.24%            | 94.09%           |\n",
        "| **Precision**       | 96.52%            | 60.93%           |\n",
        "| **Recall**          | 70.06%            | 84.94%           |\n",
        "| **F1-Score**        | 81.19%            | 70.96%           |\n",
        "| **ROC-AUC**         | 97.90%            | 97.86%           |\n",
        "\n",
        "### Final Comparison: XGBoost_1 vs Optimized Bagging Ensemble\n",
        "| Metric             | XGBoost_1        | Optimized Bagging Ensemble |\n",
        "|---------------------|------------------|-----------------------------|\n",
        "| **Accuracy**        | 90.91%           | 90.74%                     |\n",
        "| **Precision**       | 90.09%           | 89.24%                     |\n",
        "| **Recall**          | 91.94%           | 92.65%                     |\n",
        "| **F1-Score**        | 91.00%           | 90.91%                     |\n",
        "| **ROC-AUC**         | 97.66%           | 90.74%                     |\n",
        "\n",
        "*Placeholder for barchart comparisons.*\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Discussion\n",
        "The comparative analysis highlights the strengths of both XGBoost_1 and Optimized Bagging Ensemble. XGBoost_1 consistently outperformed in accuracy, precision, F1-score, and ROC-AUC, making it ideal for balanced performance across metrics. On the other hand, the Bagging Ensemble showed higher recall, indicating its potential for prioritizing positive cases in high-stakes applications.\n",
        "\n",
        "The balanced dataset approach proved crucial for addressing the initial class imbalance, allowing both models to achieve robust metrics suitable for Type 2 diabetes diagnosis.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusion\n",
        "This study demonstrates the effectiveness of machine learning techniques for diagnosing Type 2 diabetes. Key takeaways include:\n",
        "- Balancing imbalanced datasets significantly enhances model performance.\n",
        "- XGBoost_1 is recommended for overall balanced metrics and predictive reliability.\n",
        "- Optimized Bagging Ensemble is valuable for recall-focused applications, such as screening programs.\n",
        "\n",
        "Future work could explore ensemble methods combining these approaches to achieve even higher diagnostic reliability and scalability.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. References\n",
        "1. Kaggle dataset: [Diabetes Clinical Dataset (100K Rows)](https://www.kaggle.com/datasets/ziya07/diabetes-clinical-dataset100k-rows)\n",
        "2. Python libraries used: Pandas, NumPy, Scikit-learn, XGBoost, HPELM.\n",
        "3. Adaptive Synthetic Sampling Technique (ADASYN) documentation.\n",
        "4. Gradient Boosting Machines and Bagging Ensemble literature.\n",
        "\n",
        "---\n",
        "\n",
        "Let me know if there are any final tweaks or additional details you'd like included! \n"
      ],
      "metadata": {
        "id": "tnFlTc1qcCAL"
      },
      "id": "tnFlTc1qcCAL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1a4faa-a326-4330-a4f0-629430b19e9e",
      "metadata": {
        "id": "5e1a4faa-a326-4330-a4f0-629430b19e9e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yROIwbRhGt6"
      },
      "id": "5yROIwbRhGt6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcZnzc3RhGpp"
      },
      "id": "qcZnzc3RhGpp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ji--nxL4hGUO"
      },
      "id": "Ji--nxL4hGUO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Research paper"
      ],
      "metadata": {
        "id": "PI4gEKrhhGRX"
      },
      "id": "PI4gEKrhhGRX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification-Based Algorithm for Diabetes Diagnosis\n",
        "\n",
        "## Abstract\n",
        "Diabetes mellitus, particularly Type 2 diabetes, represents a significant global health concern, requiring accurate and timely diagnostics. Traditional diagnostic methods often fall short due to cost, time, and error rates. This study leverages machine learning models, including XGBoost and an optimized Bagging Ensemble, to address challenges in predictive accuracy for diabetes diagnosis. By preprocessing a clinical dataset containing 100K samples, balancing it, and evaluating performance metrics, our models achieve precision and recall suitable for automated healthcare applications. Among several approaches tested, XGBoost_1 and the optimized Bagging Ensemble emerge as the most promising tools for diabetes prediction. This paper documents the methodology, challenges faced during data preparation, and the comparative analysis of machine learning models to identify the best classifiers.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction\n",
        "Diabetes mellitus is a chronic condition impacting millions worldwide, demanding innovative approaches for early detection and diagnosis. While traditional methods are effective, they are often resource-intensive and prone to errors, limiting their scalability. Machine learning provides a promising alternative to improve diagnostic accuracy and efficiency, particularly for Type 2 diabetes.\n",
        "\n",
        "This research explores the application of advanced machine learning techniques to build a classification-based model for Type 2 diabetes diagnosis. Key challenges, such as dataset imbalance and model optimization, are addressed using novel preprocessing techniques, undersampling strategies, and algorithmic innovations. This study focuses on optimizing models for accuracy, precision, recall, and F1-score to deliver a scalable diagnostic tool suitable for diverse healthcare settings.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Methodology\n",
        "\n",
        "### 2.1 Dataset Collection and Preprocessing\n",
        "The dataset used in this study was sourced from Kaggle, containing 100,000 samples of patients' clinical data. The key features included:\n",
        "- **Demographic attributes**: Gender, age.\n",
        "- **Clinical attributes**: Hypertension, heart disease, smoking history, BMI, HbA1c level, blood glucose level.\n",
        "- **Target variable**: Diabetes (binary classification).\n",
        "\n",
        "#### Initial Cleaning\n",
        "- Unnecessary features such as location, race attributes, clinical notes, year, and inferred diabetes type were removed to streamline the dataset.\n",
        "- The dataset was analyzed to confirm its focus on Type 2 diabetes using clinical notes.\n",
        "\n",
        "#### Handling Imbalanced Data\n",
        "Initially, the dataset contained 91,500 non-diabetic samples and 8,500 diabetic samples, leading to a significant imbalance (10.76:1). After consulting with the lecturer, the imbalance was addressed using sampling techniques:\n",
        "1. **Diabetic samples**: Extracted directly from the dataset (8,500 samples).\n",
        "2. **Non-diabetic samples**: Randomly undersampled to match diabetic samples (8,500 samples).\n",
        "3. **Combined balanced dataset**: Created with equal representation of diabetic and non-diabetic samples (total of 17,000 samples).\n",
        "\n",
        "Steps in sampling using Pandas:\n",
        "- Identify diabetic and non-diabetic samples.\n",
        "- Undersample non-diabetic samples.\n",
        "- Merge balanced subsets into a new dataset (`cleaned_ziya_data.csv`).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2 Model Development\n",
        "Two key models were developed and extensively tuned:\n",
        "\n",
        "#### **XGBoost_1**\n",
        "The XGBoost model was implemented using the following configuration:\n",
        "- **Framework**: XGBoost with Gradient Boosting Machines (GBM) algorithm.\n",
        "- **Feature selection**: Applied Recursive Feature Elimination (RFE) for optimal feature extraction.\n",
        "- **Hyperparameters**:\n",
        "  - `n_estimators`: 900 (number of boosting rounds).\n",
        "  - `learning_rate`: 0.01 (ensuring better generalization).\n",
        "  - `max_depth`: 6 (tree complexity).\n",
        "  - `min_child_weight`: 3 (regularization).\n",
        "  - `subsample`: 0.8 (fraction of samples per boosting round).\n",
        "  - `colsample_bytree`: 0.9 (fraction of features used per tree).\n",
        "  - `early_stopping_rounds`: 10 (stops training on validation loss plateau).\n",
        "  - `eval_metric`: AUC-PR and logloss for performance evaluation.\n",
        "- **Training**:\n",
        "  - One-hot encoding applied to categorical features (gender, smoking history).\n",
        "  - Preprocessed data scaled for better feature representation.\n",
        "- **Evaluation**:\n",
        "  - Accuracy: 90.91%.\n",
        "  - Precision: 90.09%.\n",
        "  - Recall: 91.94%.\n",
        "  - F1-Score: 91.00%.\n",
        "  - ROC-AUC: 97.66%.\n",
        "\n",
        "#### **Optimized Bagging Ensemble**\n",
        "The Bagging Ensemble model was implemented as follows:\n",
        "- **Framework**: BaggingClassifier with Decision Trees as base estimators.\n",
        "- **Hyperparameters** (optimized via GridSearchCV):\n",
        "  - `n_estimators`: 100 (number of estimators).\n",
        "  - `max_samples`: 0.8 (fraction of samples used per estimator).\n",
        "  - `max_features`: 0.5 (fraction of features used per estimator).\n",
        "  - `estimator__max_depth`: None (no limit on tree depth).\n",
        "  - `estimator__min_samples_split`: 10 (minimum samples for tree splits).\n",
        "- **Training**:\n",
        "  - Features scaled using StandardScaler.\n",
        "- **Evaluation**:\n",
        "  - Accuracy: 90.74%.\n",
        "  - Precision: 89.24%.\n",
        "  - Recall: 92.65%.\n",
        "  - F1-Score: 90.91%.\n",
        "  - ROC-AUC: 90.74%.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Results\n",
        "\n",
        "### XGBoost Model Comparison\n",
        "Pre-SMOTE and Hybrid SMOTE models were tested using the unbalanced dataset:\n",
        "| Metric             | Pre-SMOTE         | Hybrid SMOTE     |\n",
        "|---------------------|-------------------|------------------|\n",
        "| **Accuracy**        | 97.24%            | 94.09%           |\n",
        "| **Precision**       | 96.52%            | 60.93%           |\n",
        "| **Recall**          | 70.06%            | 84.94%           |\n",
        "| **F1-Score**        | 81.19%            | 70.96%           |\n",
        "| **ROC-AUC**         | 97.90%            | 97.86%           |\n",
        "\n",
        "### Final Comparison: XGBoost_1 vs Optimized Bagging Ensemble\n",
        "| Metric             | XGBoost_1        | Optimized Bagging Ensemble |\n",
        "|---------------------|------------------|-----------------------------|\n",
        "| **Accuracy**        | 90.91%           | 90.74%                     |\n",
        "| **Precision**       | 90.09%           | 89.24%                     |\n",
        "| **Recall**          | 91.94%           | 92.65%                     |\n",
        "| **F1-Score**        | 91.00%           | 90.91%                     |\n",
        "| **ROC-AUC**         | 97.66%           | 90.74%                     |\n",
        "\n",
        "*Placeholder for barchart comparisons.*\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Discussion\n",
        "The comparative analysis highlights the strengths of both XGBoost_1 and Optimized Bagging Ensemble. XGBoost_1 consistently outperformed in accuracy, precision, F1-score, and ROC-AUC, making it ideal for balanced performance across metrics. On the other hand, the Bagging Ensemble showed higher recall, indicating its potential for prioritizing positive cases in high-stakes applications.\n",
        "\n",
        "The balanced dataset approach proved crucial for addressing the initial class imbalance, allowing both models to achieve robust metrics suitable for Type 2 diabetes diagnosis.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusion\n",
        "This study demonstrates the effectiveness of machine learning techniques for diagnosing Type 2 diabetes. Key takeaways include:\n",
        "- Balancing imbalanced datasets significantly enhances model performance.\n",
        "- XGBoost_1 is recommended for overall balanced metrics and predictive reliability.\n",
        "- Optimized Bagging Ensemble is valuable for recall-focused applications, such as screening programs.\n",
        "\n",
        "Future work could explore ensemble methods combining these approaches to achieve even higher diagnostic reliability and scalability.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. References\n",
        "1. Kaggle dataset: [Diabetes Clinical Dataset (100K Rows)](https://www.kaggle.com/datasets/ziya07/diabetes-clinical-dataset100k-rows)\n",
        "2. Python libraries used: Pandas, NumPy, Scikit-learn, XGBoost.\n",
        "3. Recursive Feature Elimination (RFE) documentation.\n",
        "4. Bagging ensemble and Gradient Boosting Machines literature.\n",
        "\n",
        "---\n",
        "\n",
        "Let me know if there are additional tweaks or visualizations you'd like integrated! \n"
      ],
      "metadata": {
        "id": "8mcIK1VwhJ3H"
      },
      "id": "8mcIK1VwhJ3H"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofLgACmlhF8z"
      },
      "id": "ofLgACmlhF8z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MP7OKuigmvc9"
      },
      "id": "MP7OKuigmvc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udadNWqQmvZS"
      },
      "id": "udadNWqQmvZS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iurzr9hAmvWz"
      },
      "id": "iurzr9hAmvWz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update research paper"
      ],
      "metadata": {
        "id": "ZiNNUOM2mvRy"
      },
      "id": "ZiNNUOM2mvRy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification-Based Algorithm for Diabetes Diagnosis\n",
        "\n",
        "## Abstract\n",
        "Diabetes mellitus, particularly Type 2 diabetes, represents a significant global health concern, requiring accurate and timely diagnostics. Traditional diagnostic methods often fall short due to cost, time, and error rates. This study explores various machine learning models, including XGBoost, HPELM, and an optimized Bagging Ensemble, for diabetes diagnosis. By addressing class imbalance through sampling techniques and testing multiple models on different configurations, this work highlights XGBoost_1 and the optimized Bagging Ensemble as the most promising solutions. The iterative nature of experimentation and the challenges encountered underscore the importance of data preprocessing and model evaluation in healthcare applications.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction\n",
        "Diabetes mellitus is a chronic condition impacting millions worldwide, demanding innovative approaches for early detection and diagnosis. While traditional methods are effective, they are often resource-intensive and prone to errors, limiting their scalability. Machine learning provides a promising alternative to improve diagnostic accuracy and efficiency, particularly for Type 2 diabetes.\n",
        "\n",
        "This study aims to develop and evaluate machine learning models for diabetes diagnosis using various data preprocessing techniques and balancing methods. The research showcases an iterative process, starting with an imbalanced dataset and progressing through oversampling techniques and balanced sampling approaches. The study's focus is on optimizing metrics such as accuracy, precision, recall, and F1-score to deliver a scalable diagnostic tool suitable for diverse healthcare settings.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Methodology\n",
        "\n",
        "### 2.1 Dataset Collection and Preprocessing\n",
        "The dataset used in this study was sourced from Kaggle and contained 100,000 clinical samples with features including:\n",
        "- **Demographic attributes**: Gender, age.\n",
        "- **Clinical attributes**: Hypertension, heart disease, smoking history, BMI, HbA1c level, blood glucose level.\n",
        "- **Target variable**: Diabetes (binary classification).\n",
        "\n",
        "#### Initial Dataset Insights\n",
        "- The original dataset was highly imbalanced, with 91,500 non-diabetic samples and 8,500 diabetic samples (10.76:1 ratio).\n",
        "- Clinical notes revealed that the dataset focused on Type 2 diabetes.\n",
        "\n",
        "#### Preprocessing and Cleaning\n",
        "- Removed irrelevant features such as location, race attributes, clinical notes, and year.\n",
        "- Applied **OneHotEncoder** to encode categorical features like gender and smoking history.\n",
        "- Standardized numerical features like age, BMI, HbA1c level, and blood glucose level.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2 Model Development Phases\n",
        "\n",
        "#### **Phase 1: Pre-SMOTE and Hybrid SMOTE Models**\n",
        "1. **Pre-SMOTE Model**:\n",
        "   - Built using XGBoost with calculated class weights (scale_pos_weight = 10.76) to handle class imbalance.\n",
        "   - Hyperparameters:\n",
        "     - `n_estimators`: 900\n",
        "     - `learning_rate`: 0.01\n",
        "     - `max_depth`: 6\n",
        "     - `min_child_weight`: 3\n",
        "     - `subsample`: 0.8\n",
        "     - `colsample_bytree`: 0.9\n",
        "   - Threshold: 0.87 (favoring high precision).\n",
        "   - Metrics:\n",
        "     - Accuracy: 97.21%\n",
        "     - Precision: 96.05%\n",
        "     - Recall: 70.06%\n",
        "     - F1-Score: 81.02%\n",
        "     - ROC-AUC: 97.90%\n",
        "\n",
        "2. **Hybrid SMOTE Model**:\n",
        "   - Applied SMOTE to oversample the minority class to a 2:1 ratio.\n",
        "   - XGBoost trained with reduced class weight (scale_pos_weight = 5).\n",
        "   - Threshold: 0.51 (favoring balanced precision and recall).\n",
        "   - Metrics:\n",
        "     - Accuracy: 94.09%\n",
        "     - Precision: 60.93%\n",
        "     - Recall: 84.94%\n",
        "     - F1-Score: 70.96%\n",
        "     - ROC-AUC: 97.86%\n",
        "\n",
        "#### **Phase 2: HPELM Models**\n",
        "HPELM models were implemented as part of exploratory work to evaluate Extreme Learning Machines (ELM) for diabetes diagnosis.\n",
        "- Features:\n",
        "  - **Number of neurons**: 3,000 with sigmoid activation.\n",
        "  - Applied 5-fold and 10-fold cross-validation for robust evaluation.\n",
        "- Best Metrics:\n",
        "  - Accuracy: 95.93%\n",
        "  - Precision: 77.96%\n",
        "  - Recall: 72.82%\n",
        "  - F1-Score: 75.30%\n",
        "  - ROC-AUC: 95.31%\n",
        "\n",
        "#### **Phase 3: Balanced Dataset Models**\n",
        "Following a consultation with a lecturer, a new dataset was created by sampling equal numbers of diabetic and non-diabetic samples:\n",
        "- **Balanced Dataset Creation**:\n",
        "  - Undersampled non-diabetic samples to match 8,500 diabetic samples.\n",
        "  - Combined both subsets into a new balanced dataset (17,000 samples).\n",
        "\n",
        "1. **XGBoost_1**:\n",
        "   - Hyperparameters:\n",
        "     - `n_estimators`: 900\n",
        "     - `learning_rate`: 0.01\n",
        "     - `max_depth`: 6\n",
        "     - `min_child_weight`: 3\n",
        "     - `subsample`: 0.8\n",
        "     - `colsample_bytree`: 0.9\n",
        "   - Metrics:\n",
        "     - Accuracy: 90.91%\n",
        "     - Precision: 90.09%\n",
        "     - Recall: 91.94%\n",
        "     - F1-Score: 91.00%\n",
        "     - ROC-AUC: 97.66%\n",
        "\n",
        "2. **Optimized Bagging Ensemble**:\n",
        "   - Built using Decision Trees as base estimators with hyperparameter tuning:\n",
        "     - `n_estimators`: 100\n",
        "     - `max_samples`: 0.8\n",
        "     - `max_features`: 0.5\n",
        "     - `estimator__max_depth`: None\n",
        "     - `estimator__min_samples_split`: 10\n",
        "   - Metrics:\n",
        "     - Accuracy: 90.74%\n",
        "     - Precision: 89.24%\n",
        "     - Recall: 92.65%\n",
        "     - F1-Score: 90.91%\n",
        "     - ROC-AUC: 90.74%\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Results\n",
        "\n",
        "### Comparison of Models\n",
        "#### Pre-SMOTE vs Hybrid SMOTE:\n",
        "| Metric             | Pre-SMOTE         | Hybrid SMOTE     |\n",
        "|---------------------|-------------------|------------------|\n",
        "| **Accuracy**        | 97.21%            | 94.09%           |\n",
        "| **Precision**       | 96.05%            | 60.93%           |\n",
        "| **Recall**          | 70.06%            | 84.94%           |\n",
        "| **F1-Score**        | 81.02%            | 70.96%           |\n",
        "| **ROC-AUC**         | 97.90%            | 97.86%           |\n",
        "\n",
        "#### Final Models: XGBoost_1 vs Optimized Bagging:\n",
        "| Metric             | XGBoost_1        | Optimized Bagging Ensemble |\n",
        "|---------------------|------------------|-----------------------------|\n",
        "| **Accuracy**        | 90.91%           | 90.74%                     |\n",
        "| **Precision**       | 90.09%           | 89.24%                     |\n",
        "| **Recall**          | 91.94%           | 92.65%                     |\n",
        "| **F1-Score**        | 91.00%           | 90.91%                     |\n",
        "| **ROC-AUC**         | 97.66%           | 90.74%                     |\n",
        "\n",
        "*Placeholder for barchart comparisons.*\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Discussion\n",
        "The progression from imbalanced datasets to a balanced dataset significantly improved model performance. While Pre-SMOTE and Hybrid SMOTE models provided insights into handling class imbalance, the balanced dataset approach yielded superior results. Among the final models:\n",
        "- **XGBoost_1** exhibited balanced metrics across accuracy, precision, recall, and F1-score, making it an excellent choice for general-purpose diagnostics.\n",
        "- **Optimized Bagging Ensemble** prioritized recall, which is critical in screening applications where missing a diagnosis carries significant risks.\n",
        "\n",
        "HPELM models showed potential but underperformed compared to XGBoost and Bagging ensembles, emphasizing the importance of feature representation in achieving high performance.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Conclusion\n",
        "This study demonstrates the effectiveness of machine learning techniques for diagnosing Type 2 diabetes. Key takeaways include:\n",
        "- Balancing datasets is crucial for addressing class imbalance and improving model performance.\n",
        "- XGBoost_1 is recommended for balanced metrics, while the Optimized Bagging Ensemble excels in recall-focused applications.\n",
        "- Exploring diverse algorithms like HPELM provides valuable insights but may require further optimization for clinical adoption.\n",
        "\n",
        "Future work could explore ensemble methods combining these approaches to achieve even higher diagnostic reliability and scalability.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. References\n",
        "1. Kaggle dataset: [Diabetes Clinical Dataset (100K Rows)](https://www.kaggle.com/datasets/ziya07/diabetes-clinical-dataset100k-rows)\n",
        "2. Python libraries used: Pandas, NumPy, Scikit-learn, XGBoost, HPELM.\n",
        "3. Recursive Feature Elimination (RFE) documentation.\n",
        "4. SMOTE and sampling techniques in imbalanced data literature.\n",
        "\n",
        "---\n",
        "\n",
        "Let me know if this revised version captures your work fully or if additional tweaks are needed! \n"
      ],
      "metadata": {
        "id": "l2rR9wMmmx09"
      },
      "id": "l2rR9wMmmx09"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjPKbOrRmunk"
      },
      "id": "EjPKbOrRmunk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZaR9F2vvZRt"
      },
      "id": "gZaR9F2vvZRt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inc-0p29vZPA"
      },
      "id": "inc-0p29vZPA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6_GNxF87vZHQ"
      },
      "id": "6_GNxF87vZHQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rlgaQ6pIvZDU"
      },
      "id": "rlgaQ6pIvZDU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QV_jDEiAvZAo"
      },
      "id": "QV_jDEiAvZAo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final article\n",
        "\n",
        "# Classification-Based Algorithm for Diabetes Diagnosis\n",
        "\n",
        "## Abstract\n",
        "Diabetes mellitus, particularly Type 2 diabetes, represents a significant global health concern, requiring accurate and timely diagnostics. Traditional diagnostic methods often fall short due to cost, time, and error rates. This study explores various machine learning models, including XGBoost, HPELM, and an optimized Bagging Ensemble, for diabetes diagnosis. By addressing class imbalance through sampling techniques and testing multiple models on different configurations, this work highlights XGBoost_1 and the optimized Bagging Ensemble as the most promising solutions. The iterative nature of experimentation and the challenges encountered underscore the importance of data preprocessing and model evaluation in healthcare applications.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction\n",
        "Diabetes mellitus is a chronic condition impacting millions worldwide, demanding innovative approaches for early detection and diagnosis. While traditional methods are effective, they are often resource-intensive and prone to errors, limiting their scalability. Machine learning provides a promising alternative to improve diagnostic accuracy and efficiency, particularly for Type 2 diabetes.\n",
        "\n",
        "This study aims to develop and evaluate machine learning models for diabetes diagnosis using various data preprocessing techniques and balancing methods. The research showcases an iterative process, starting with an imbalanced dataset and progressing through oversampling techniques and balanced sampling approaches. The study's focus is on optimizing metrics such as accuracy, precision, recall, and F1-score to deliver a scalable diagnostic tool suitable for diverse healthcare settings.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Methodology\n",
        "\n",
        "### 2.1 Dataset Collection and Preprocessing\n",
        "The dataset used in this study was sourced from Kaggle and contained 100,000 clinical samples. The features in the dataset included:\n",
        "- **Temporal Information**: Year of data entry.\n",
        "- **Demographic Attributes**:\n",
        "  - **Gender**: Male, Female, or Other.\n",
        "  - **Age**: Patient's age in years.\n",
        "  - **Location**: Geographic region where the data was collected.\n",
        "- **Ethnicity**: Encoded as binary indicators for:\n",
        "  - African-American, Asian, Caucasian, Hispanic, and Other.\n",
        "- **Clinical Attributes**:\n",
        "  - **Hypertension**: Binary indicator (0 = No, 1 = Yes).\n",
        "  - **Heart Disease**: Binary indicator (0 = No, 1 = Yes).\n",
        "  - **Smoking History**: Categories such as never, former, current, etc.\n",
        "  - **BMI (Body Mass Index)**: Numeric value.\n",
        "  - **HbA1c Level**: Glycated hemoglobin percentage.\n",
        "  - **Blood Glucose Level**: Numeric blood sugar level.\n",
        "- **Clinical Notes**: Textual observations providing additional context about each sample.\n",
        "- **Target Variable (Diabetes)**: Binary classification (0 = Non-diabetic, 1 = Diabetic).\n",
        "\n",
        "#### Initial Dataset Insights\n",
        "- The original dataset was highly imbalanced, with 91,500 non-diabetic samples and 8,500 diabetic samples (10.76:1 ratio).\n",
        "- Clinical notes provided context confirming that the dataset focused on Type 2 diabetes.\n",
        "\n",
        "#### Preprocessing and Cleaning\n",
        "- Removed irrelevant features such as location, race attributes, clinical notes, and year.\n",
        "- Applied **OneHotEncoder** to encode categorical features like gender and smoking history.\n",
        "- Standardized numerical features like age, BMI, HbA1c level, and blood glucose level.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.2 Model Development Phases\n",
        "\n",
        "#### **Phase 1: Pre-SMOTE and Hybrid SMOTE Models**\n",
        "1. **Pre-SMOTE Model**:\n",
        "   - Built using XGBoost with calculated class weights (scale_pos_weight = 10.76) to handle class imbalance.\n",
        "   - Hyperparameters:\n",
        "     - `n_estimators`: 900\n",
        "     - `learning_rate`: 0.01\n",
        "     - `max_depth`: 6\n",
        "     - `min_child_weight`: 3\n",
        "     - `subsample`: 0.8\n",
        "     - `colsample_bytree`: 0.9\n",
        "   - Threshold: 0.87 (favoring high precision).\n",
        "   - Metrics:\n",
        "     - Accuracy: 97.21%\n",
        "     - Precision: 96.05%\n",
        "     - Recall: 70.06%\n",
        "     - F1-Score: 81.02%\n",
        "     - ROC-AUC: 97.90%\n",
        "\n",
        "2. **Hybrid SMOTE Model**:\n",
        "   - Applied SMOTE to oversample the minority class to a 2:1 ratio.\n",
        "   - XGBoost trained with reduced class weight (scale_pos_weight = 5).\n",
        "   - Threshold: 0.51 (favoring balanced precision and recall).\n",
        "   - Metrics:\n",
        "     - Accuracy: 94.09%\n",
        "     - Precision: 60.93%\n",
        "     - Recall: 84.94%\n",
        "     - F1-Score: 70.96%\n",
        "     - ROC-AUC: 97.86%\n",
        "\n",
        "#### **Phase 2: HPELM Models**\n",
        "HPELM models were implemented as part of exploratory work to evaluate Extreme Learning Machines (ELM) for diabetes diagnosis. After balancing the dataset, these models were revisited but failed to deliver competitive results, leading to the adoption of the Bagging Ensemble model.\n",
        "- Features:\n",
        "  - **Number of neurons**: 3,000 with sigmoid activation.\n",
        "  - Applied 5-fold and 10-fold cross-validation for robust evaluation.\n",
        "- Metrics:\n",
        "  - Accuracy (Balanced Dataset): Range from 82.56% to 85.52%.\n",
        "  - ROC-AUC (Balanced Dataset): Range from 88.21% to 89.98%.\n",
        "\n",
        "#### **Phase 3: Balanced Dataset Models**\n",
        "Following a consultation with a lecturer, a new dataset was created by sampling equal numbers of diabetic and non-diabetic samples:\n",
        "- **Balanced Dataset Creation**:\n",
        "  - Undersampled non-diabetic samples to match 8,500 diabetic samples.\n",
        "  - Combined both subsets into a new balanced dataset (17,000 samples).\n",
        "\n",
        "1. After balancing the dataset, HPELM models were attempted again. Despite modifications and cross-validation, the metrics remained suboptimal:\n",
        "   - Accuracy: Range from 82.56% to 84.88%.\n",
        "   - ROC-AUC: Range from 88.21% to 89.98%.\n",
        "\n",
        "   These results prompted a shift to the Bagging Ensemble model.\n",
        "\n",
        "2. **XGBoost_1**:\n",
        "   - Hyperparameters:\n",
        "     - `n_estimators`: 900\n",
        "     - `learning_rate`: 0.01\n",
        "     - `max_depth`: 6\n",
        "     - `min_child_weight`: 3\n",
        "     - `subsample`: 0.8\n",
        "     - `colsample_bytree`: 0.9\n",
        "   - Metrics:\n",
        "     - Accuracy: 90.91%\n",
        "     - Precision: 90.09%\n",
        "     - Recall: 91.94%\n",
        "     - F1-Score: 91.00%\n",
        "     - ROC-AUC: 97.66%\n",
        "\n",
        "3. **Optimized Bagging Ensemble**:\n",
        "   - Built using Decision Trees as base estimators with hyperparameter tuning:\n",
        "     - `n_estimators`: 100\n",
        "     - `max_samples`: 0.8\n",
        "     - `max_features`: 0.5\n",
        "     - `estimator__max_depth`: None\n",
        "     - `estimator__min_samples_split`: 10\n",
        "   - Metrics:\n",
        "     - Accuracy: 90.74%\n",
        "     - Precision: 89.24%\n",
        "     - Recall: 92.65%\n",
        "     - F1-Score: 90.91%\n",
        "     - ROC-AUC: 90.74%\n",
        "\n",
        "---\n",
        "\n",
        "### 2.3 Computational Resources\n",
        "The study utilized the following computational setups:\n",
        "1. **HP Laptop**:\n",
        "   - **Processor**: Intel Core i3 (10th Gen).\n",
        "   - **Storage**: 256GB SATA M.2 SSD.\n",
        "   - **Memory**: 8GB DDR4 system memory.\n",
        "   - **Operating System**: Ubuntu.\n",
        "   - **Environment**:\n",
        "     - Anaconda (Conda version 25.3.0).\n",
        "     - Jupyter Notebook (version 7.3.3).\n",
        "     - Python (version 3.12.9).\n",
        "2. **Google Colab Free Version**:\n",
        "   - Used for collaborative development and testing.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Results\n",
        "\n",
        "### Comparison of Models\n",
        "#### Pre-SMOTE vs Hybrid SMOTE:\n",
        "| Metric             | Pre-SMOTE         | Hybrid SMOTE     |\n",
        "|---------------------|-------------------|------------------|\n",
        "| **Accuracy**        | 97.21%            | 94.09%           |\n",
        "| **Precision**       | 96.05%            | 60.93%           |\n",
        "| **Recall**          | 70.06%            | 84.94%           |\n",
        "| **F1-Score**        | 81.02%            | 70.96%           |\n",
        "| **ROC-AUC**         | 97.90%            | 97.86%           |\n",
        "\n",
        "#### Final Models: XGBoost_1 vs Optimized Bagging:\n",
        "| Metric             | XGBoost_1        | Optimized Bagging Ensemble |\n",
        "|---------------------|------------------|-----------------------------|\n",
        "| **Accuracy**        | 90.91%           | 90.74%                     |\n",
        "| **Precision**       | 90.09%           | 89.24%                     |\n",
        "| **Recall**          | 91.94%           | 92.65%                     |\n",
        "| **F1-Score**        | 91.00%           | 90.91%                     |\n",
        "| **ROC-AUC**         | 97.66%           | 90.74%                     |\n",
        "\n",
        "*Placeholder for barchart comparisons.*\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Discussion\n",
        "The progression from imbalanced datasets to a balanced dataset significantly improved model performance. While Pre-SMOTE and Hybrid SMOTE models provided insights into handling class imbalance, the balanced dataset approach yielded superior results. Among the final models:\n",
        "- **XGBoost_1** exhibited balanced metrics across accuracy, precision, recall, and F1-score, making it an excellent choice for general-purpose diagnostics.\n",
        "- **Optimized Bagging Ensemble** prioritized recall, which is critical in screening applications where missing a diagnosis carries significant risks.\n",
        "\n",
        "HPELM models showed potential but underperformed"
      ],
      "metadata": {
        "id": "ZsycxkZ4vaLY"
      },
      "id": "ZsycxkZ4vaLY"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "alMK-M6BvY6q"
      },
      "id": "alMK-M6BvY6q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IX0mqBjP9aZa"
      },
      "id": "IX0mqBjP9aZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PPTX version"
      ],
      "metadata": {
        "id": "T1HyFpf-9Z8W"
      },
      "id": "T1HyFpf-9Z8W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Title Slide\n",
        "## Classification-Based Algorithm for Diabetes Diagnosis\n",
        "### By Group 3(BCT 3A)\n",
        "\n",
        "---\n",
        "\n",
        "# Slide 1: Introduction\n",
        "## The Challenge of Type 2 Diabetes\n",
        "- A chronic condition impacting millions worldwide.\n",
        "- Early detection is critical to reduce complications.\n",
        "- Machine learning offers innovative solutions for diagnosis.\n",
        "\n",
        "---\n",
        "\n",
        "# Slide 2: Objectives\n",
        "## Key Goals of the Study\n",
        "- Develop and evaluate machine learning models for Type 2 diabetes diagnosis.\n",
        "- Address challenges like data imbalance and model optimization.\n",
        "- Deliver scalable diagnostic tools suitable for healthcare.\n",
        "\n",
        "---\n",
        "\n",
        "# Slide 3: Dataset Description\n",
        "## Clinical Data Overview\n",
        "- **Total Samples**: 100,000.\n",
        "- **Features**:\n",
        "  - Temporal: Year of data entry.\n",
        "  - Demographic: Gender, age, location.\n",
        "  - Ethnicity: African-American, Asian, Caucasian, Hispanic, Other.\n",
        "  - Clinical: Hypertension, heart disease, smoking history, BMI, HbA1c level, blood glucose level.\n",
        "  - Notes: Text observations per sample.\n",
        "  - Target: Binary classification (Diabetic or Non-diabetic).\n",
        "\n",
        "---\n",
        "\n",
        "# Slide 4: Methodology Overview\n",
        "## Development Phases\n",
        "1. **Phase 1**: Pre-SMOTE and Hybrid SMOTE Models.\n",
        "2. **Phase 2**: Exploratory HPELM Models.\n",
        "3. **Phase 3**: Balanced Dataset and Final Models.\n",
        "\n",
        "---\n",
        "\n",
        "# Slide 5: Phase 1 - Pre-SMOTE and Hybrid SMOTE\n",
        "## Addressing Class Imbalance\n",
        "- **Pre-SMOTE**:\n",
        "  - XGBoost with calculated class weights.\n",
        "  - Precision: 96.05%, Recall: 70.06%.\n",
        "- **Hybrid SMOTE**:\n",
        "  - Oversampling minority class.\n",
        "  - Precision: 60.93%, Recall: 84.94%.\n",
        "\n",
        "---\n",
        "\n",
        "# Slide 6: Phase 2 - HPELM Models"
      ],
      "metadata": {
        "id": "NdX8wVQS9pFG"
      },
      "id": "NdX8wVQS9pFG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ka18cqD09ZbB"
      },
      "id": "Ka18cqD09ZbB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zg0s9-y69ZHL"
      },
      "id": "Zg0s9-y69ZHL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iSBw_qUy9Y3b"
      },
      "id": "iSBw_qUy9Y3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RAh3MMe69Yj3"
      },
      "id": "RAh3MMe69Yj3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWAwZKBI9YBF"
      },
      "id": "uWAwZKBI9YBF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E76dTNPt9XPD"
      },
      "id": "E76dTNPt9XPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75uTSB1H9W1Q"
      },
      "id": "75uTSB1H9W1Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZKCH1089WhJ"
      },
      "id": "iZKCH1089WhJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}