{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frederick-Teye/ML-models/blob/main/Copy_of_last_last.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Yk8x0g3YEKBR",
        "outputId": "d7355a75-061f-4762-a2c4-1b8541daf411"
      },
      "id": "Yk8x0g3YEKBR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17264ce-78ac-4910-a5bb-52f2abb4b47e",
      "metadata": {
        "id": "c17264ce-78ac-4910-a5bb-52f2abb4b47e",
        "outputId": "e0c1fdcf-b630-458b-d913-48c382e91c6c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>smoking_history</th>\n",
              "      <th>bmi</th>\n",
              "      <th>hbA1c_level</th>\n",
              "      <th>blood_glucose_level</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Info</td>\n",
              "      <td>37.23</td>\n",
              "      <td>6.5</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>never</td>\n",
              "      <td>27.32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>No Info</td>\n",
              "      <td>27.32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>current</td>\n",
              "      <td>27.32</td>\n",
              "      <td>5.0</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>never</td>\n",
              "      <td>38.48</td>\n",
              "      <td>5.7</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
              "0  Female  56.0             0              0         No Info  37.23   \n",
              "1    Male  29.0             0              0           never  27.32   \n",
              "2  Female  26.0             0              0         No Info  27.32   \n",
              "3    Male  50.0             0              0         current  27.32   \n",
              "4  Female  56.0             0              0           never  38.48   \n",
              "\n",
              "   hbA1c_level  blood_glucose_level  diabetes  \n",
              "0          6.5                   80         0  \n",
              "1          3.5                  160         0  \n",
              "2          4.0                  145         0  \n",
              "3          5.0                  145         0  \n",
              "4          5.7                  155         1  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "ziya_data = pd.read_csv('cleaned_ziya_data.csv')\n",
        "ziya_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692fd18c-360f-434c-ac27-c4c5baadaf99",
      "metadata": {
        "id": "692fd18c-360f-434c-ac27-c4c5baadaf99",
        "outputId": "bbcb2d53-9017-4db0-e7a1-eefa2a19c9bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gender  hypertension  heart_disease\n",
              "Female  0             0                7620\n",
              "                      1                 439\n",
              "        1             0                1207\n",
              "                      1                 184\n",
              "Male    0             0                5674\n",
              "                      1                 673\n",
              "        1             0                 979\n",
              "                      1                 224\n",
              "Name: diabetes, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ziya_data.groupby(['gender', 'hypertension', 'heart_disease']).diabetes.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51a966b3-ee91-4781-a5a4-5af14a5ca533",
      "metadata": {
        "id": "51a966b3-ee91-4781-a5a4-5af14a5ca533",
        "outputId": "0ad9a1e5-922a-4773-ead4-e443139d051b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diabetes\n",
              "0    8500\n",
              "1    8500\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ziya_data.diabetes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2393b7c8-491e-41db-a26a-09ce6b075b95",
      "metadata": {
        "id": "2393b7c8-491e-41db-a26a-09ce6b075b95"
      },
      "outputs": [],
      "source": [
        "# Balanced code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf34c66-2960-459e-982d-ef35afef3150",
      "metadata": {
        "id": "8cf34c66-2960-459e-982d-ef35afef3150",
        "outputId": "d5d78240-2f73-47ad-f579-c2d283a37c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation at Threshold = 0.50\n",
            "==================================================\n",
            "Accuracy: 0.9088\n",
            "Precision: 0.9013\n",
            "Recall: 0.9182\n",
            "F1-Score: 0.9097\n",
            "ROC-AUC: 0.9767\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      1700\n",
            "           1       0.90      0.92      0.91      1700\n",
            "\n",
            "    accuracy                           0.91      3400\n",
            "   macro avg       0.91      0.91      0.91      3400\n",
            "weighted avg       0.91      0.91      0.91      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])  # Feature matrix\n",
        "y = ziya_data['diabetes']  # Target variable\n",
        "\n",
        "# Train-test split (stratify to maintain balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Categorical Encoding (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# XGBoost Classifier (No class weighting for balanced data)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=900,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.8,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold = 0.5  # Standard for balanced data\n",
        "y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "# Model Evaluation\n",
        "print(f\"\\nEvaluation at Threshold = {threshold:.2f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Store metrics for visualization\n",
        "recall_model0 = recall_score(y_test, y_pred)\n",
        "precision_model0 = precision_score(y_test, y_pred)\n",
        "f1_model0 = f1_score(y_test, y_pred)\n",
        "accuracy_model0 = accuracy_score(y_test, y_pred)\n",
        "roc_auc_model0 = roc_auc_score(y_test, y_pred_proba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c47a17f-4002-4130-ac64-f04b5171dede",
      "metadata": {
        "id": "9c47a17f-4002-4130-ac64-f04b5171dede",
        "outputId": "f4979e5e-5d3e-41ca-e8ec-bebd15a6cf4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation at Threshold = 0.50\n",
            "==================================================\n",
            "Accuracy: 0.9088\n",
            "Precision: 0.9013\n",
            "Recall: 0.9182\n",
            "F1-Score: 0.9097\n",
            "ROC-AUC: 0.9767\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      1700\n",
            "           1       0.90      0.92      0.91      1700\n",
            "\n",
            "    accuracy                           0.91      3400\n",
            "   macro avg       0.91      0.91      0.91      3400\n",
            "weighted avg       0.91      0.91      0.91      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])  # Feature matrix\n",
        "y = ziya_data['diabetes']  # Target variable\n",
        "\n",
        "# Train-test split (stratify to maintain balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Feature selection\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Categorical Encoding (One-Hot Encoding)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# XGBoost Classifier (No class weighting for balanced data)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1000,            # Number of boosting rounds\n",
        "    learning_rate=0.01,          # Learning rate (lower = better generalization)\n",
        "    early_stopping_rounds=10,    # Stop training if validation loss doesn't improve\n",
        "    eval_metric=['aucpr', 'logloss'],  # Evaluation metrics\n",
        "    random_state=42,             # Random seed for reproducibility\n",
        "    max_depth=6,                 # Tree depth (higher = more complex model)\n",
        "    min_child_weight=3,          # Regularization parameter\n",
        "    subsample=0.8,               # Fraction of samples used per boosting round\n",
        "    colsample_bytree=0.9         # Fraction of features used per tree\n",
        ")\n",
        "\n",
        "# Training with validation set\n",
        "eval_set = [(X_train_preprocessed, y_train), (X_test_preprocessed, y_test)]\n",
        "xgb_model.fit(X_train_preprocessed, y_train, eval_set=eval_set, verbose=False)\n",
        "\n",
        "# Get probabilities\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_preprocessed)[:, 1]\n",
        "\n",
        "# Decision Threshold\n",
        "threshold = 0.5  # Standard for balanced data\n",
        "y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "# Model Evaluation\n",
        "print(f\"\\nEvaluation at Threshold = {threshold:.2f}\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Store metrics for visualization\n",
        "recall_model0 = recall_score(y_test, y_pred)\n",
        "precision_model0 = precision_score(y_test, y_pred)\n",
        "f1_model0 = f1_score(y_test, y_pred)\n",
        "accuracy_model0 = accuracy_score(y_test, y_pred)\n",
        "roc_auc_model0 = roc_auc_score(y_test, y_pred_proba)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "086aa2fd-9a7d-4ace-baa4-549cafb54e30",
      "metadata": {
        "id": "086aa2fd-9a7d-4ace-baa4-549cafb54e30"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c3ebff-cc51-4e8f-b018-176291be9a5d",
      "metadata": {
        "id": "61c3ebff-cc51-4e8f-b018-176291be9a5d"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning using Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2aef54b-2313-4893-8702-16d91f2edbd3",
      "metadata": {
        "id": "c2aef54b-2313-4893-8702-16d91f2edbd3",
        "outputId": "bac85063-3edb-4b81-d3ef-00887372a09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit-learn version: 1.6.1\n",
            "xgboost version: 2.1.1\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import xgboost\n",
        "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"xgboost version: {xgboost.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gab9mgSXDgO_"
      },
      "id": "gab9mgSXDgO_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d84c94c-d470-400e-b53f-ca3fb0593070",
      "metadata": {
        "id": "2d84c94c-d470-400e-b53f-ca3fb0593070"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65983605-336c-483a-80a9-747b66759ee0",
      "metadata": {
        "id": "65983605-336c-483a-80a9-747b66759ee0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c57cbfb1-52a8-41a3-9bcc-a82ee9a81939",
      "metadata": {
        "id": "c57cbfb1-52a8-41a3-9bcc-a82ee9a81939"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b841bde-a513-4b3e-bcab-ed5fa3add2f0",
      "metadata": {
        "id": "3b841bde-a513-4b3e-bcab-ed5fa3add2f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8912fc3-3b44-459b-ab5f-aa89c35d7e07",
      "metadata": {
        "id": "f8912fc3-3b44-459b-ab5f-aa89c35d7e07"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d3df9a-f5d6-4b8f-a1ae-87e3db124ca3",
      "metadata": {
        "id": "b5d3df9a-f5d6-4b8f-a1ae-87e3db124ca3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b22a00-20f8-4b0d-bc7b-28c2a34aeb5a",
      "metadata": {
        "id": "30b22a00-20f8-4b0d-bc7b-28c2a34aeb5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5537458b-4b47-4ae0-b6ab-7e40872f00de",
      "metadata": {
        "id": "5537458b-4b47-4ae0-b6ab-7e40872f00de"
      },
      "source": [
        "# hpelm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de71911-b82f-46b9-8f05-1a2318c55e26",
      "metadata": {
        "id": "9de71911-b82f-46b9-8f05-1a2318c55e26",
        "outputId": "d67a2637-e0fe-400f-fd20-889d44f9b2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " X_train_preprocessed.shape[1]:\n",
            "  12\n",
            "y_train.shape[1]:\n",
            " 2\n",
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8756\n",
            "Precision: 0.8771\n",
            "Recall: 0.8735\n",
            "F1-Score: 0.8753\n",
            "ROC-AUC: 0.9452\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.88      1700\n",
            "           1       0.88      0.87      0.88      1700\n",
            "\n",
            "    accuracy                           0.88      3400\n",
            "   macro avg       0.88      0.88      0.88      3400\n",
            "weighted avg       0.88      0.88      0.88      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "\n",
        "print(f' X_train_preprocessed.shape[1]:\\n  {X_train_preprocessed.shape[1]}')\n",
        "print(f'y_train.shape[1]:\\n {y_train.shape[1]}')\n",
        "\n",
        "# Define the ELM model\n",
        "num_neurons = 3000  # Adjust as needed\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\")  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Apply threshold for classification\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12fb87b-98a2-40bd-b3d0-a28e3f4e0cf1",
      "metadata": {
        "id": "b12fb87b-98a2-40bd-b3d0-a28e3f4e0cf1",
        "outputId": "929e84d0-41a5-48b6-cbbd-e1f6173bb4df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8729\n",
            "Precision: 0.8747\n",
            "Recall: 0.8706\n",
            "F1-Score: 0.8726\n",
            "ROC-AUC: 0.9399\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.87      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Define the ELM model\n",
        "num_neurons = 3000  # Adjust as needed\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\")  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Apply threshold for classification\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7ac0ab-cb56-4b79-97f2-b25f9c00ce16",
      "metadata": {
        "id": "6c7ac0ab-cb56-4b79-97f2-b25f9c00ce16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c6439c-d175-4fc0-bb9d-c1cee7a3d68f",
      "metadata": {
        "id": "46c6439c-d175-4fc0-bb9d-c1cee7a3d68f",
        "outputId": "a7613351-a057-4d89-9603-f344ad6cc6a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8412\n",
            "Precision: 0.8244\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8452\n",
            "ROC-AUC: 0.8932\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84      1700\n",
            "           1       0.82      0.87      0.85      1700\n",
            "\n",
            "    accuracy                           0.84      3400\n",
            "   macro avg       0.84      0.84      0.84      3400\n",
            "weighted avg       0.84      0.84      0.84      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load data (same as HPELM)\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Feature Engineering: Create BMI categories\n",
        "X['bmi_category'] = pd.cut(X['bmi'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease',\n",
        "       'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history', 'bmi_category']  # Added bmi_category\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', RobustScaler(), num_features),  # Changed to RobustScaler\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features)  # Removed drop='first'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Dynamically adjust the number of neurons\n",
        "num_neurons = min(5000, X_train_preprocessed.shape[0] // 2)\n",
        "\n",
        "# Define the ELM model\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model with class weights\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\", W=class_weight_dict)  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Determine best threshold using Precision-Recall Curve\n",
        "precisions, recalls, thresholds = precision_recall_curve(np.argmax(y_test, axis=1), y_pred_proba[:, 1])\n",
        "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
        "\n",
        "# Apply optimized threshold\n",
        "y_pred = (y_pred_proba[:, 1] >= best_threshold).astype(int)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1e7dfd-9dde-4ff3-b682-1405eddaa7ca",
      "metadata": {
        "id": "3b1e7dfd-9dde-4ff3-b682-1405eddaa7ca",
        "outputId": "389da268-fffc-433f-bdcc-0675fe33faad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8297\n",
            "Precision: 0.8081\n",
            "Recall: 0.8647\n",
            "F1-Score: 0.8355\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.79      0.82      1700\n",
            "           1       0.81      0.86      0.84      1700\n",
            "\n",
            "    accuracy                           0.83      3400\n",
            "   macro avg       0.83      0.83      0.83      3400\n",
            "weighted avg       0.83      0.83      0.83      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import hpelm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load data (same as HPELM)\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Feature Engineering: Create BMI categories\n",
        "X['bmi_category'] = pd.cut(X['bmi'], bins=[0, 18.5, 25, 30, np.inf], labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Convert target variable to one-hot encoding\n",
        "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
        "y_onehot = ohe.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_onehot, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define available features\n",
        "available_features = X_train.columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "num_features = ['age', 'hypertension', 'heart_disease',\n",
        "       'bmi', 'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history', 'bmi_category']  # Added bmi_category\n",
        "\n",
        "# Remove missing features\n",
        "num_features = [col for col in num_features if col in available_features]\n",
        "cat_features = [col for col in cat_features if col in available_features]\n",
        "\n",
        "# Define preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', RobustScaler(), num_features),  # Changed to RobustScaler\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features)  # Removed drop='first'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Dynamically adjust the number of neurons\n",
        "num_neurons = min(5000, X_train_preprocessed.shape[0] // 2)\n",
        "\n",
        "# Define the ELM model\n",
        "elm_model = hpelm.ELM(X_train_preprocessed.shape[1], y_train.shape[1])\n",
        "elm_model.add_neurons(num_neurons, \"sigm\")  # Using sigmoid activation\n",
        "\n",
        "# Train the model with class weights\n",
        "elm_model.train(X_train_preprocessed, y_train, \"c\", W=class_weight_dict)  # Classification mode\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = elm_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Determine best threshold using Precision-Recall Curve\n",
        "precisions, recalls, thresholds = precision_recall_curve(np.argmax(y_test, axis=1), y_pred_proba[:, 1])\n",
        "best_threshold = thresholds[np.argmax(precisions + recalls)]\n",
        "\n",
        "# Apply optimized threshold\n",
        "y_pred = (y_pred_proba[:, 1] >= best_threshold).astype(int)\n",
        "\n",
        "# Convert y_test back to single-column labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test_labels, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test_labels, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642e4170-59f9-4d9d-ac33-ea2f4a390f8c",
      "metadata": {
        "id": "642e4170-59f9-4d9d-ac33-ea2f4a390f8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0bafaf-6026-4e88-98b0-26db7580f8a7",
      "metadata": {
        "id": "0d0bafaf-6026-4e88-98b0-26db7580f8a7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb03c02-ceaa-4495-9297-2f5977a084f7",
      "metadata": {
        "id": "0cb03c02-ceaa-4495-9297-2f5977a084f7",
        "outputId": "5638f08b-0f58-40b1-ae52-5d31414ece2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: 8\n",
            "X_train_processed.shape[1]: [ 1.   1.   0.   0.   0.   0.  44.   0.   0.  26.5  4.  85. ]\n",
            "X_train_processed: [[  1.     0.     0.   ...  27.32   6.1  155.  ]\n",
            " [  1.     1.     0.   ...  26.5    4.    85.  ]\n",
            " [  0.     0.     0.   ...  25.65   5.8  158.  ]\n",
            " ...\n",
            " [  1.     0.     0.   ...  27.77   6.6  160.  ]\n",
            " [  0.     0.     0.   ...  27.32   4.8  145.  ]\n",
            " [  0.     0.     0.   ...  37.76   7.   200.  ]]\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "T has wrong dimensionality: expected 2, found 1",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m y_train_array = np.array(y_train).reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[32m     54\u001b[39m y_pred = model.predict(X_test_processed)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/hpelm/hp_elm.py:84\u001b[39m, in \u001b[36mHPELM.train\u001b[39m\u001b[34m(self, fX, fT, *args, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Universal training interface for HP-ELM model.\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m \u001b[33;03mAlways trains a basic ELM model without model structure selection.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33;03m    batch (int, optional): batch size for ELM, overwrites batch size from the initialization\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# TODO: move to h5py, because I don't need pyTables features\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# TODO: move to h5py with MPI async IO (driver='mpio')\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# TODO: explain why I don't support parallel processing (huge amount of data to transfer, or fast enough)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m X, T = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_checkdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m._train_parse_args(args, kwargs)\n\u001b[32m     87\u001b[39m istart = \u001b[32m0\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/hpelm/elm.py:556\u001b[39m, in \u001b[36mELM._checkdata\u001b[39m\u001b[34m(self, X, T)\u001b[39m\n\u001b[32m    553\u001b[39m             T = T.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    554\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(T.shape) == \u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mT must have 2 dimensions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m T.shape[\u001b[32m1\u001b[39m] == \u001b[38;5;28mself\u001b[39m.nnet.outputs, \u001b[33m\"\u001b[39m\u001b[33mT has wrong dimensionality: expected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m, found \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % \\\n\u001b[32m    557\u001b[39m                                             (\u001b[38;5;28mself\u001b[39m.nnet.outputs, T.shape[\u001b[32m1\u001b[39m])\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (T \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    560\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m X.shape[\u001b[32m0\u001b[39m] == T.shape[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mX and T cannot have different number of samples\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mAssertionError\u001b[39m: T has wrong dimensionality: expected 2, found 1"
          ]
        }
      ],
      "source": [
        "from hpelm import HPELM\n",
        "\n",
        "import numpy as np\n",
        "# Convert y_train to a NumPy array\n",
        "# y_train_array = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Preprocessing pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Initialize and train HPELM model\n",
        "inputs = X_train_processed.shape[1]  # Number of features\n",
        "outputs = len(set(y_train))  # Number of classes or regression target dimensionality\n",
        "model = HPELM(inputs, outputs, classification='c')  # Use 'c' for classification\n",
        "\n",
        "\n",
        "print(f'X: {len(X.columns)}')\n",
        "print(f'X_train_processed.shape[1]: {X_train_processed[1]}')\n",
        "print(f'X_train_processed: {X_train_processed}')\n",
        "\n",
        "\n",
        "y_train_array = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Train model\n",
        "model.train(X_train_processed, y_train_array)\n",
        "\n",
        "# Predict using the model\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87184bbe-ca4d-41a7-8c85-280e3e79e3b6",
      "metadata": {
        "id": "87184bbe-ca4d-41a7-8c85-280e3e79e3b6",
        "outputId": "b79cebe8-652b-447b-a727-9bc914b6f9d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/frederick/miniconda3/lib/python3.12/site-packages/hpelm/nnets/slfn.py:62: RuntimeWarning: overflow encountered in exp\n",
            "  self.func[\"sigm\"] = lambda X, W, B: 1 / (1 + np.exp(np.dot(X, W) + B))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covariance matrix is not full rank; solving with SVD (slow)\n",
            "This happened because you have duplicated or too many neurons\n",
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8315\n",
            "Precision: 0.8078\n",
            "Recall: 0.8700\n",
            "F1-Score: 0.8377\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82      1700\n",
            "           1       0.81      0.87      0.84      1700\n",
            "\n",
            "    accuracy                           0.83      3400\n",
            "   macro avg       0.83      0.83      0.83      3400\n",
            "weighted avg       0.83      0.83      0.83      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from hpelm import HPELM\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "\n",
        "# Load data\n",
        "X = ziya_data.drop(columns=['diabetes'])\n",
        "y = ziya_data['diabetes']\n",
        "\n",
        "# Split data with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define numerical and categorical features\n",
        "num_features = ['age', 'hypertension', 'heart_disease', 'bmi',\n",
        "                'hbA1c_level', 'blood_glucose_level']\n",
        "cat_features = ['gender', 'smoking_history']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), cat_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# One-hot encode the target variable\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))  # For predictions\n",
        "\n",
        "# Initialize HPELM model\n",
        "inputs = X_train_processed.shape[1]  # Number of features\n",
        "outputs = y_train_encoded.shape[1]  # Number of classes\n",
        "model = HPELM(inputs, outputs, classification='c')  # Use 'c' for classification\n",
        "\n",
        "# Add neurons to the model\n",
        "model.add_neurons(3000, 'sigm')  # Add 100 sigmoid neurons, for example\n",
        "\n",
        "# Train model\n",
        "model.train(X_train_processed, y_train_encoded)\n",
        "\n",
        "# Predict using the model\n",
        "y_pred_encoded = model.predict(X_test_processed)\n",
        "\n",
        "# Decode predictions back to original labels\n",
        "y_pred = encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4006ed6e-2aa3-424f-9693-c09f0c9bba1c",
      "metadata": {
        "id": "4006ed6e-2aa3-424f-9693-c09f0c9bba1c"
      },
      "outputs": [],
      "source": [
        "help(HPELM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fadc4ca-1a57-4b76-b29a-f57d6285869e",
      "metadata": {
        "id": "7fadc4ca-1a57-4b76-b29a-f57d6285869e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a710b74-ec4e-4971-b43c-a67f442a6451",
      "metadata": {
        "id": "0a710b74-ec4e-4971-b43c-a67f442a6451"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81d3ea6-7eae-407c-86e3-fbaaceb00fb5",
      "metadata": {
        "id": "f81d3ea6-7eae-407c-86e3-fbaaceb00fb5",
        "outputId": "b0d22c29-a973-4e9c-bbed-21b9007de20a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8779\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8724\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(random_state=42, max_iter=500, solver='saga', C=0.1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e731a829-7f87-433f-a823-80ebbedad735",
      "metadata": {
        "id": "e731a829-7f87-433f-a823-80ebbedad735",
        "outputId": "3bf277fe-9ec0-417d-d811-e5196204ed55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8779\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8724\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report, precision_recall_curve)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression(random_state=42, max_iter=500, solver='lbfgs', C=0.1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff1b3ad-f20f-4601-ab61-38e7b7a58189",
      "metadata": {
        "id": "1ff1b3ad-f20f-4601-ab61-38e7b7a58189"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9970db3a-f9e8-4c39-8e89-db6017343495",
      "metadata": {
        "id": "9970db3a-f9e8-4c39-8e89-db6017343495",
        "outputId": "628240dd-6a52-4a96-af0b-d6b9c6ae4011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 0.1, 'max_iter': 100, 'solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {\n",
        "    'solver': ['lbfgs', 'saga'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'max_iter': [100, 200, 500]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=LogisticRegression(),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Use appropriate scoring metric\n",
        "    cv=5  # Number of folds in cross-validation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00ead63b-3b8b-4a91-b751-2df95ea1b7e4",
      "metadata": {
        "id": "00ead63b-3b8b-4a91-b751-2df95ea1b7e4"
      },
      "outputs": [],
      "source": [
        "# help(GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa4e7e3-bcbf-4813-a01c-f3501d51d7f4",
      "metadata": {
        "id": "0fa4e7e3-bcbf-4813-a01c-f3501d51d7f4",
        "outputId": "55c99330-949f-48c7-fff1-783f188e1083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8779\n",
            "Recall: 0.8671\n",
            "F1-Score: 0.8724\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1700\n",
            "           1       0.88      0.87      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize Logistic Regression model with the tuned parameters\n",
        "model = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=100,\n",
        "    solver='saga',\n",
        "    C=0.1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa9b3efd-2ebc-44bc-91ac-8880ee0f9968",
      "metadata": {
        "id": "aa9b3efd-2ebc-44bc-91ac-8880ee0f9968",
        "outputId": "849a59ed-5c9f-4e48-d35a-0fc71fe12523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics\n",
            "=====================================\n",
            "Accuracy: 0.8724\n",
            "Precision: 0.8777\n",
            "Recall: 0.8653\n",
            "F1-Score: 0.8714\n",
            "ROC-AUC: 0.8724\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Regularized Logistic Regression model\n",
        "# L1 Regularization (lasso): `penalty='l1'`\n",
        "# L2 Regularization (ridge): `penalty='l2'`\n",
        "model = LogisticRegression(\n",
        "    random_state=42,\n",
        "    solver='saga',\n",
        "    C=0.1,  # Regularization strength\n",
        "    penalty='l1'  # Use L1 or L2\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics\")\n",
        "print(\"=====================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c58093-1423-4acb-93a7-148b55448fe7",
      "metadata": {
        "id": "b9c58093-1423-4acb-93a7-148b55448fe7",
        "outputId": "fccd949c-afa3-40d7-e4a0-06ed47293959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
            "Best Cross-Validation Accuracy: 0.8866911764705883\n",
            "Evaluation Metrics for Best Model\n",
            "=====================================\n",
            "Accuracy: 0.8732\n",
            "Precision: 0.8761\n",
            "Recall: 0.8694\n",
            "F1-Score: 0.8727\n",
            "ROC-AUC: 0.8732\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the parameter grid for regularization strength\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Values to test for regularization strength\n",
        "    'solver': ['saga'],  # Saga supports both L1 and L2 regularization\n",
        "    'penalty': ['l1', 'l2']  # Test both L1 (Lasso) and L2 (Ridge)\n",
        "}\n",
        "\n",
        "# Grid search for best regularization strength\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=500),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # You can switch to precision, recall, or other metrics\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Print the best parameters and corresponding score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model for evaluation on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the best model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Evaluation Metrics for Best Model\")\n",
        "print(\"=====================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f353c6-f0da-4b56-b75f-5c2a1f19985a",
      "metadata": {
        "id": "c0f353c6-f0da-4b56-b75f-5c2a1f19985a",
        "outputId": "6115de7a-8a4e-424e-cb96-612857438f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 0.01, 'l1_ratio': 0.5, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
            "Best Cross-Validation Accuracy: 0.8857352941176471\n",
            "\n",
            "Evaluation Metrics for ElasticNet Regularization\n",
            "====================================================\n",
            "Accuracy: 0.8712\n",
            "Precision: 0.8760\n",
            "Recall: 0.8647\n",
            "F1-Score: 0.8703\n",
            "ROC-AUC: 0.8712\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the parameter grid for ElasticNet regularization\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization strengths\n",
        "    'l1_ratio': [0.2, 0.5, 0.8],  # Mix of L1 and L2 penalties\n",
        "    'solver': ['saga'],  # Saga supports ElasticNet\n",
        "    'penalty': ['elasticnet']  # Use ElasticNet penalty\n",
        "}\n",
        "\n",
        "# Grid search to find the best ElasticNet parameters\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=500),\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # You can also use precision, recall, etc.\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Print the best parameters and corresponding score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model for evaluation on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the best model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics for ElasticNet Regularization\")\n",
        "print(\"====================================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9920dd7-e1e1-4507-b45b-00d838e772f0",
      "metadata": {
        "id": "a9920dd7-e1e1-4507-b45b-00d838e772f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c913bcca-2e27-40dd-ad44-0dee24a36975",
      "metadata": {
        "id": "c913bcca-2e27-40dd-ad44-0dee24a36975"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3862eb-82b6-40a8-94f5-4737584cac1a",
      "metadata": {
        "id": "fc3862eb-82b6-40a8-94f5-4737584cac1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a604a851-3297-48db-a9b9-6c3e6cb15ed6",
      "metadata": {
        "id": "a604a851-3297-48db-a9b9-6c3e6cb15ed6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2015041-410e-44c7-8f12-1d6dd9f7f2c6",
      "metadata": {
        "id": "d2015041-410e-44c7-8f12-1d6dd9f7f2c6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9dc64cb-943e-4c1b-ba8a-3ffddf25ef6c",
      "metadata": {
        "id": "e9dc64cb-943e-4c1b-ba8a-3ffddf25ef6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89395c3-f6f5-4f5e-9593-987bd2b2ddc1",
      "metadata": {
        "id": "e89395c3-f6f5-4f5e-9593-987bd2b2ddc1"
      },
      "outputs": [],
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc3002c-9368-4220-a1e1-26d4bf9438be",
      "metadata": {
        "id": "5bc3002c-9368-4220-a1e1-26d4bf9438be",
        "outputId": "180e39a7-42af-49e5-8044-a04ecd8c21ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.9021\n",
            "Precision: 0.8926\n",
            "Recall: 0.9141\n",
            "F1-Score: 0.9032\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      1700\n",
            "           1       0.89      0.91      0.90      1700\n",
            "\n",
            "    accuracy                           0.90      3400\n",
            "   macro avg       0.90      0.90      0.90      3400\n",
            "weighted avg       0.90      0.90      0.90      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=2500, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747c557c-e2b6-4bca-a5b7-a923011c3f54",
      "metadata": {
        "id": "747c557c-e2b6-4bca-a5b7-a923011c3f54"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2535d06b-b704-497a-97a1-e1a2e721e6b4",
      "metadata": {
        "id": "2535d06b-b704-497a-97a1-e1a2e721e6b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d8c89d-add6-4066-b854-c7f6999b3492",
      "metadata": {
        "id": "20d8c89d-add6-4066-b854-c7f6999b3492"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machine(SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9620f191-1513-4b19-b975-6d8a05be4e3c",
      "metadata": {
        "id": "9620f191-1513-4b19-b975-6d8a05be4e3c",
        "outputId": "4556d1f9-76d1-4ea3-dcb6-6e81f591b526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8803\n",
            "Precision: 0.8761\n",
            "Recall: 0.8859\n",
            "F1-Score: 0.8810\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88      1700\n",
            "           1       0.88      0.89      0.88      1700\n",
            "\n",
            "    accuracy                           0.88      3400\n",
            "   macro avg       0.88      0.88      0.88      3400\n",
            "weighted avg       0.88      0.88      0.88      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize SVM model\n",
        "model = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374e97b4-2200-4c73-ba18-900c7859f5bf",
      "metadata": {
        "id": "374e97b4-2200-4c73-ba18-900c7859f5bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6065a4c-f46a-46c7-9eff-5e0aa3ff6a32",
      "metadata": {
        "id": "a6065a4c-f46a-46c7-9eff-5e0aa3ff6a32"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312b82e9-dd3b-4d2a-b267-2333176f2126",
      "metadata": {
        "id": "312b82e9-dd3b-4d2a-b267-2333176f2126"
      },
      "outputs": [],
      "source": [
        "# K-Nearest Neighbourh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5439170-6fef-4e0a-9b4e-ea8e62e45a04",
      "metadata": {
        "id": "f5439170-6fef-4e0a-9b4e-ea8e62e45a04",
        "outputId": "c2c3e254-2eab-46be-e2a8-916a8dbd81d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics\n",
            "==================================================\n",
            "Accuracy: 0.8679\n",
            "Precision: 0.8564\n",
            "Recall: 0.8841\n",
            "F1-Score: 0.8700\n",
            "ROC-AUC: 0.8817\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87      1700\n",
            "           1       0.86      0.88      0.87      1700\n",
            "\n",
            "    accuracy                           0.87      3400\n",
            "   macro avg       0.87      0.87      0.87      3400\n",
            "weighted avg       0.87      0.87      0.87      3400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize KNN model\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"\\nEvaluation Metrics\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3fd1412-5de3-4504-9b96-d6080b7c86af",
      "metadata": {
        "id": "d3fd1412-5de3-4504-9b96-d6080b7c86af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5246d9-51ee-411c-a035-56d4a5af1232",
      "metadata": {
        "id": "de5246d9-51ee-411c-a035-56d4a5af1232"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9aa1caac-0ce3-424b-b2d3-000caed7e360",
      "metadata": {
        "id": "9aa1caac-0ce3-424b-b2d3-000caed7e360"
      },
      "source": [
        "# Voting Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79e4965-57e6-4746-af78-48f1f0bec0d7",
      "metadata": {
        "id": "f79e4965-57e6-4746-af78-48f1f0bec0d7",
        "outputId": "07e78ed7-45e2-45d3-8a30-3653f5b587b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Ensemble Metrics\n",
            "=================================\n",
            "Accuracy: 0.8888\n",
            "Precision: 0.8865\n",
            "Recall: 0.8918\n",
            "F1-Score: 0.8891\n",
            "ROC-AUC: 0.8888\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize individual models\n",
        "log_reg = LogisticRegression(random_state=42, C=0.01, penalty='l2', solver='saga', max_iter=500)  # Best-tuned LR model\n",
        "rf_clf = RandomForestClassifier(random_state=42, n_estimators=100)  # Random Forest\n",
        "svm_clf = SVC(probability=True, random_state=42)  # Support Vector Machine with probability for soft voting\n",
        "\n",
        "# Create the VotingClassifier (use 'soft' or 'hard' voting)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_reg), ('rf', rf_clf), ('svm', svm_clf)],\n",
        "    voting='soft'  # For soft voting based on probabilities\n",
        ")\n",
        "\n",
        "# Train the ensemble model\n",
        "voting_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = voting_clf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Voting Ensemble Metrics\")\n",
        "print(\"=================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7841555-1e8e-4383-8e98-9d15faad3b06",
      "metadata": {
        "id": "c7841555-1e8e-4383-8e98-9d15faad3b06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89dcdda-4b8a-4bc3-ac72-c508ab3f99c0",
      "metadata": {
        "id": "e89dcdda-4b8a-4bc3-ac72-c508ab3f99c0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0a7541f8-6a7f-4562-93c9-e347ec867d6b",
      "metadata": {
        "id": "0a7541f8-6a7f-4562-93c9-e347ec867d6b"
      },
      "source": [
        "# Stacking Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23f6c8b-ac15-4cf7-beec-5b1d3039d3f7",
      "metadata": {
        "id": "e23f6c8b-ac15-4cf7-beec-5b1d3039d3f7",
        "outputId": "340c41cc-4e88-4a27-b9cf-baccd8c9cb2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stacking Ensemble Metrics\n",
            "=================================\n",
            "Accuracy: 0.8974\n",
            "Precision: 0.8907\n",
            "Recall: 0.9059\n",
            "F1-Score: 0.8982\n",
            "ROC-AUC: 0.8974\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),  # Random Forest\n",
        "    ('svm', SVC(probability=True, random_state=42))  # Support Vector Machine with probability output\n",
        "]\n",
        "\n",
        "# Define the meta-model (Logistic Regression in this case)\n",
        "meta_model = LogisticRegression(random_state=42, solver='saga', C=0.1, penalty='l2')\n",
        "\n",
        "# Create the StackingClassifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5  # Cross-validation during training of the meta-model\n",
        ")\n",
        "\n",
        "# Train the Stacking Ensemble\n",
        "stacking_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = stacking_clf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the Stacking Ensemble\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Stacking Ensemble Metrics\")\n",
        "print(\"=================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff81a593-a81a-47b6-8c12-809b708eb0d1",
      "metadata": {
        "id": "ff81a593-a81a-47b6-8c12-809b708eb0d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "02719a1a-e10c-47ca-ab78-da8e41cb7fbe",
      "metadata": {
        "id": "02719a1a-e10c-47ca-ab78-da8e41cb7fbe"
      },
      "source": [
        "## Tuning the Base Models and Meta-Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625e9b65-509c-44d8-a4a0-249267ddef12",
      "metadata": {
        "id": "625e9b65-509c-44d8-a4a0-249267ddef12"
      },
      "source": [
        "### Step 1: Tune the Base Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399a63f3-0503-4d5a-9af1-8578fc28c794",
      "metadata": {
        "id": "399a63f3-0503-4d5a-9af1-8578fc28c794",
        "outputId": "3709857b-8d5f-4db7-d86d-d5c9af09e4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Random Forest Parameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Best SVM Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Tuning Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees\n",
        "    'max_depth': [10, 20, None],     # Maximum depth of trees\n",
        "    'min_samples_split': [2, 5, 10]  # Minimum samples to split a node\n",
        "}\n",
        "\n",
        "rf_search = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid=rf_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "rf_search.fit(X_train_processed, y_train)\n",
        "best_rf = rf_search.best_estimator_\n",
        "print(\"Best Random Forest Parameters:\", rf_search.best_params_)\n",
        "\n",
        "# Tuning SVM\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10],           # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
        "    'gamma': ['scale', 'auto']    # Kernel coefficient\n",
        "}\n",
        "\n",
        "svm_search = GridSearchCV(\n",
        "    SVC(probability=True, random_state=42),\n",
        "    param_grid=svm_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "svm_search.fit(X_train_processed, y_train)\n",
        "best_svm = svm_search.best_estimator_\n",
        "print(\"Best SVM Parameters:\", svm_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2664cb8b-9fcf-41f4-91e0-fd3264fbb4ac",
      "metadata": {
        "id": "2664cb8b-9fcf-41f4-91e0-fd3264fbb4ac"
      },
      "source": [
        "### Step 2: Tune the Meta-Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a33dab-30be-4df6-a379-2c2407b60c33",
      "metadata": {
        "id": "31a33dab-30be-4df6-a379-2c2407b60c33",
        "outputId": "d2a80c4c-02f3-4b32-ded1-45fda85dd2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Logistic Regression Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Tuning Logistic Regression (meta-model)\n",
        "lr_param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
        "    'solver': ['saga'],       # Solver for ElasticNet\n",
        "    'penalty': ['l1', 'l2']   # Regularization type\n",
        "}\n",
        "\n",
        "lr_search = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, max_iter=500),\n",
        "    param_grid=lr_param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5\n",
        ")\n",
        "lr_search.fit(X_train_processed, y_train)\n",
        "best_meta_model = lr_search.best_estimator_\n",
        "print(\"Best Logistic Regression Parameters:\", lr_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66228d97-567e-486f-9641-66bd6910483c",
      "metadata": {
        "id": "66228d97-567e-486f-9641-66bd6910483c"
      },
      "source": [
        "### Step 3: Integrate Tuned Models into Stacking Ensemble\n",
        "Finally, use the tuned base models (best_rf, best_svm) and the meta-model (best_meta_model) in the stacking classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3955e299-15ed-4d80-8c79-4fb1d89a4cb7",
      "metadata": {
        "id": "3955e299-15ed-4d80-8c79-4fb1d89a4cb7",
        "outputId": "b52d8bdf-ec8f-4a0e-8947-1f69a0cccd4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimized Stacking Ensemble Metrics\n",
            "======================================\n",
            "Accuracy: 0.9000\n",
            "Precision: 0.8981\n",
            "Recall: 0.9024\n",
            "F1-Score: 0.9002\n",
            "ROC-AUC: 0.9000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Define tuned models\n",
        "base_models = [\n",
        "    ('rf', best_rf),\n",
        "    ('svm', best_svm)\n",
        "]\n",
        "\n",
        "# Stacking classifier with tuned models\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=best_meta_model,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Train the optimized Stacking Ensemble\n",
        "stacking_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Evaluate the ensemble\n",
        "y_pred = stacking_clf.predict(X_test_processed)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nOptimized Stacking Ensemble Metrics\")\n",
        "print(\"======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7a7eaa-c0a2-4243-aac2-3434f32b7cdc",
      "metadata": {
        "id": "2f7a7eaa-c0a2-4243-aac2-3434f32b7cdc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97058ee5-0442-4cf5-8783-4547ed66a44f",
      "metadata": {
        "id": "97058ee5-0442-4cf5-8783-4547ed66a44f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f797821-63bb-40b0-b705-09c198c3b180",
      "metadata": {
        "id": "6f797821-63bb-40b0-b705-09c198c3b180"
      },
      "source": [
        "# Bagging Ensemble Model\n",
        "Bagging, short for Bootstrap Aggregating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05cd957b-a65b-464e-bb9b-a49fc386250a",
      "metadata": {
        "id": "05cd957b-a65b-464e-bb9b-a49fc386250a",
        "outputId": "6e927216-502c-449a-83df-5a6d86861c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bagging Ensemble Metrics\n",
            "=======================================\n",
            "Accuracy: 0.8976\n",
            "Precision: 0.8890\n",
            "Recall: 0.9088\n",
            "F1-Score: 0.8988\n",
            "ROC-AUC: 0.8976\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Initialize base model (Decision Tree in this case)\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Create BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_model,  # Correct keyword for base model\n",
        "    n_estimators=50,       # Number of base models\n",
        "    max_samples=0.8,       # Fraction of samples used for training each base model\n",
        "    max_features=0.8,      # Fraction of features used for training each base model\n",
        "    bootstrap=True,        # Enable bootstrapping of samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the Bagging model\n",
        "bagging_clf.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bagging_clf.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the Bagging model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nBagging Ensemble Metrics\")\n",
        "print(\"=======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86e8f79-e819-4b8b-bc53-a35a8f17bcf2",
      "metadata": {
        "id": "b86e8f79-e819-4b8b-bc53-a35a8f17bcf2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f676a889-d27d-4b67-888d-20590758d8c3",
      "metadata": {
        "id": "f676a889-d27d-4b67-888d-20590758d8c3"
      },
      "source": [
        "## hyperparameter Tuning for Bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4324f710-67fc-47b8-83cc-e01cdd1d3817",
      "metadata": {
        "id": "4324f710-67fc-47b8-83cc-e01cdd1d3817",
        "outputId": "449d36fa-d87c-4b77-9116-be5ed0f1791a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'estimator__max_depth': None, 'estimator__min_samples_split': 10, 'max_features': 0.5, 'max_samples': 0.8, 'n_estimators': 100}\n",
            "Best Cross-Validation Accuracy: 0.9098529411764705\n",
            "\n",
            "Optimized Bagging Ensemble Metrics\n",
            "=======================================\n",
            "Accuracy: 0.9074\n",
            "Precision: 0.8924\n",
            "Recall: 0.9265\n",
            "F1-Score: 0.9091\n",
            "ROC-AUC: 0.9074\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_processed = scaler.fit_transform(X_train_processed)\n",
        "X_test_processed = scaler.transform(X_test_processed)\n",
        "\n",
        "# Define the Bagging model with a Decision Tree as the base estimator\n",
        "base_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid for Bagging\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],  # Number of estimators\n",
        "    'max_samples': [0.5, 0.8, 1.0],  # Fraction of training samples for each base estimator\n",
        "    'max_features': [0.5, 0.8, 1.0],  # Fraction of features for each base estimator\n",
        "    'estimator__max_depth': [3, 5, None],  # Max depth of the base Decision Tree\n",
        "    'estimator__min_samples_split': [2, 5, 10]  # Min samples to split a node\n",
        "}\n",
        "\n",
        "# GridSearchCV for BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=base_model,\n",
        "    bootstrap=True,  # Bootstrap samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=bagging_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',  # Evaluate using accuracy\n",
        "    cv=5  # 5-fold cross-validation\n",
        ")\n",
        "\n",
        "# Fit the grid search on the training data\n",
        "grid_search.fit(X_train_processed, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_bagging_clf = grid_search.best_estimator_\n",
        "y_pred = best_bagging_clf.predict(X_test_processed)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nOptimized Bagging Ensemble Metrics\")\n",
        "print(\"=======================================\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1596b66-8c12-4615-9ad1-19365d0911f3",
      "metadata": {
        "id": "b1596b66-8c12-4615-9ad1-19365d0911f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c7a5be1-79e7-403d-98fa-aebc9afdac92",
      "metadata": {
        "id": "5c7a5be1-79e7-403d-98fa-aebc9afdac92"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d32ce40-8b2e-4d66-8683-efc1c6f94f8c",
      "metadata": {
        "id": "8d32ce40-8b2e-4d66-8683-efc1c6f94f8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1a4faa-a326-4330-a4f0-629430b19e9e",
      "metadata": {
        "id": "5e1a4faa-a326-4330-a4f0-629430b19e9e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}